{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from pyspark.context import SparkContext\n",
    "from os import path\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alltweets = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_connection(database):\n",
    "    try:\n",
    "        conn = sqlite3.connect(database)\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTweets(username): \n",
    "    sql = '''select tweet_text from tweets where user_screen_name=?'''\n",
    "    database = \"../twitterApp/twitter.sqlite\"\n",
    "    conn = create_connection(database)\n",
    "    \n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql,(username,))\n",
    "    \n",
    "    tweets = cur.fetchall()\n",
    "    \n",
    "    usertweets = []\n",
    "    \n",
    "    for tweet in tweets: \n",
    "        \n",
    "        usertweets.append((tweet[0]))\n",
    "    \n",
    "    #alltweets.extend(' '.join(usertweets))\n",
    "    \n",
    "    return usertweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTrueNegatives(database):\n",
    "    conn = create_connection(database)\n",
    "    sql = '''select user_screen_name from search_results where isDepressed=0 ORDER BY ROWID DESC LIMIT 322'''\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql)\n",
    "    users = cur.fetchall()\n",
    "    \n",
    "    return users\n",
    "    #for user in users: \n",
    "    #   user_tweets = getTweets(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTruePositives(database):    \n",
    "    conn = create_connection(database)\n",
    "    sql = '''select user_screen_name from search_results where isDepressed=\"True\"'''\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql)\n",
    "    users = cur.fetchall()\n",
    "    \n",
    "    return users\n",
    "    #for user in users: \n",
    "    #    user_tweets = getTweets(str(user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "\n",
    "def gettfidf(usertweets): \n",
    "    temp_df = spark.createDataFrame(usertweets,['tweet'])\n",
    "    tokenizer = Tokenizer(inputCol=\"tweet\", outputCol=\"words\")\n",
    "    wordsData = tokenizer.transform(temp_df)\n",
    "\n",
    "    hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=20)\n",
    "    featurizedData = hashingTF.transform(wordsData)\n",
    "    idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "    idfModel = idf.fit(featurizedData)\n",
    "    rescaledData = idfModel.transform(featurizedData)\n",
    "    \n",
    "    return rescaledData.select(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = getTruePositives(\"../twitterApp/twitter.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alltweets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_nonascii(text):\n",
    "    return ''.join([i if ord(i) < 128 else ' ' for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for user in test: \n",
    "    t = getTweets(user[0])    \n",
    "    alltweets.append(remove_nonascii(' '.join(t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the RDDs for users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trueNegatives = getTrueNegatives(\"../twitterApp/twitter.sqlite\")\n",
    "truePositives = getTruePositives(\"../twitterApp/twitter.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alltweets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for user in trueNegatives: \n",
    "    t = getTweets(user[0]) \n",
    "    alltweets.append([user[0], 0, remove_nonascii(' '.join(t))])\n",
    "\n",
    "for user in truePositives:\n",
    "    t = getTweets(user[0])\n",
    "    alltweets.append([user[0], 1, remove_nonascii(' '.join(t))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweetRDD = sc.parallelize(alltweets).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweetDF = tweetRDD.toDF([\"username\",\"label\",\"tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- username: string (nullable = true)\n",
      " |-- label: long (nullable = true)\n",
      " |-- tweet: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweetDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"tweet\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(tweetDF)\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=20)\n",
    "featurizedData = hashingTF.transform(wordsData)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "tfidftweets = idfModel.transform(featurizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|       username|label|               tweet|               words|         rawFeatures|            features|\n",
      "+---------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|   PopoffSierra|    0|RT @jacksfilms: \"...|[rt, @jacksfilms:...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|      dhenwikan|    0|Carnival and He -...|[carnival, and, h...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "| JosephineAlice|    0|Guess I'll just r...|[guess, i'll, jus...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|   JoseJaimes95|    0|Being able to mut...|[being, able, to,...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|      lyriczbot|    0|I miss that happy...|[i, miss, that, h...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|  grillmeeting1|    0|@1HkipUrdKrXXzdk ...|[@1hkipurdkrxxzdk...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|bustercalamity1|    0|@marcushegreat3 G...|[@marcushegreat3,...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|    _Coopavelli|    0|THE COOKOUT IS FR...|[the, cookout, is...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|     LeahEbooks|    0|?? the love good ...|[??, the, love, g...|(20,[0,1,2,4,5,6,...|(20,[0,1,2,4,5,6,...|\n",
      "|   KeyOfConceit|    0|@EthereaIVirago M...|[@ethereaivirago,...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "| goofy_goober33|    0|@Treyarch hey you...|[@treyarch, hey, ...|(20,[0,3,4,5,8,9,...|(20,[0,3,4,5,8,9,...|\n",
      "|      kalenstar|    0|gospel. let shit ...|[gospel., let, sh...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|        VBMagz4|    0|@EBJunkies coulda...|[@ebjunkies, coul...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|   lizkennedyyy|    0|RT @UberFacts: Re...|[rt, @uberfacts:,...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|       BRick441|    0|@Ian_height76 Hey...|[@ian_height76, h...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|    Hello_Davey|    0|@PRINCE_OF_NY For...|[@prince_of_ny, f...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|mangledindustr1|    0|@hleborezka1337 H...|[@hleborezka1337,...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|  travisworland|    0|What a day it has...|[what, a, day, it...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|    PuffyPanda2|    0|I should just mak...|[i, should, just,...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|     thottinsos|    0|@bizzleown ifb @A...|[@bizzleown, ifb,...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "+---------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidftweets.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized using L^1 norm\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|normFeatures                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.032591106549712826,0.08340048945781986,0.030010977281193896,0.05169725049954928,0.0413194205761345,0.05691590039224825,0.038161377340361284,0.07165100610495508,0.05608386252096416,0.05658973477395456,0.03725870605348249,0.05002066820424728,0.04276962486562839,0.10160059009848327,0.03620438363059918,0.027029534496298142,0.051466789093088175,0.04191228195073868,0.05313934799273264,0.04017694811780819])       |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.035531576354220364,0.07504515797872807,0.033661493388208764,0.03989061489087895,0.05057119630846068,0.07625203329007156,0.05603936247404978,0.051271327113606116,0.03490821536554983,0.054756018295254755,0.029928080741592415,0.0612629650802921,0.050185938664013434,0.08683962276513059,0.04470315556136033,0.030609863298618124,0.04390242391636751,0.03978366954264603,0.05141414418077494,0.053443140790175724])    |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.03593457569505255,0.048137332912243036,0.026537085665658933,0.05434921235597059,0.041780919515819255,0.05838640764634094,0.039209730017081765,0.04627580133996677,0.0691186665034533,0.07224132784738466,0.04219996678792248,0.05384853094324502,0.07275978556519638,0.07416817105415233,0.03596773985966315,0.023941104595599033,0.06308288022441189,0.047865232041133354,0.04852219946326612,0.04567332996643831])      |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.0350930201002845,0.050999597249113224,0.027673352993367206,0.041331728316347856,0.03848694623554719,0.05704561191513415,0.036665728397168015,0.049406390090078106,0.06489702074259754,0.06089882475161815,0.04506435203100827,0.055127900738559985,0.07469989098009065,0.08173025664885974,0.0374183090292938,0.028833997618119753,0.05464484558472872,0.056082308706013155,0.054833454908760404,0.04906646296330948])    |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.05495867978673711,0.052192964312467574,0.023192356977170033,0.05960837604747518,0.023797187205289443,0.08149127320979274,0.03784911107251535,0.05162944850080489,0.08819566568933969,0.07718180839332342,0.048006984548364405,0.05563251301572967,0.023312414845468435,0.06997581804447309,0.026404302871400116,0.03355200805293339,0.06838583382615133,0.04023344611441435,0.047714195667943486,0.03668561181820617])    |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.04560461444891344,0.0559530114921069,0.028502884030570903,0.04792224562363441,0.037968114941072544,0.0684603508909063,0.05305677194045238,0.04571169617538304,0.06555663327031307,0.03080715790090783,0.02732015848716392,0.13895815114336307,0.07746741738940371,0.03765319298999846,0.039364701762271116,0.05012597595784946,0.021377163022928174,0.03765319298999846,0.05256845060169049,0.037968114941072544])        |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.039613488419036794,0.06512243520938493,0.024587682466988357,0.03444964134258476,0.032561217604692466,0.06397790535051456,0.041011477788791384,0.037241961159475465,0.06146920616747089,0.041011477788791384,0.017184575616716335,0.1085248575415707,0.10700954594630144,0.04265193690034304,0.047573314234998006,0.039309629123131136,0.025953664826265488,0.057416068904307935,0.06353040433086991,0.049799509277764956])|\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.03523966369363943,0.05176896133310238,0.033015561496986166,0.04748457240305381,0.03700753059153503,0.05258916393638209,0.04798909598483626,0.037730078490200825,0.04752165026849132,0.050066546027469856,0.04352451956430687,0.049395946052505114,0.09480130907151589,0.10580156288555427,0.041163188701897266,0.025048564263947106,0.04828772991400521,0.049591700303439325,0.05564393928596844,0.04632871573116324])    |\n",
      "|(20,[0,1,2,4,5,6,8,9,10,12,13,14,15,16,17,18,19],[0.0556922631997938,0.13356055677577905,0.03635467181097651,0.01843817431127344,0.10775580582753995,0.010350927160773543,0.0556922631997938,0.08453257181298393,0.056201311034068335,0.0073315158482209295,0.06077852102095234,0.07378353206910372,0.011041439530453206,0.07834487025526549,0.05799173293920561,0.023392508307444534,0.12875733489637167])                                                                          |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.036573884081695845,0.05128350606153241,0.02767753389966172,0.055794005031382266,0.03187893620041204,0.06647796344164697,0.07478770887185282,0.058655617982482165,0.05930900121356082,0.04154872715102935,0.03316132026594191,0.060684773348696784,0.05452175232808903,0.06054243099149991,0.04867136609120581,0.03318715359101071,0.058320517860001475,0.046297153111146995,0.050729183119984575,0.049897465357166666])   |\n",
      "|(20,[0,3,4,5,8,9,10,15,16,17,18,19],[0.13413661008528827,0.0805448264805958,0.14106368169053088,0.1610896529611916,0.06706830504264413,0.0805448264805958,0.0803566369487923,0.026806412120002173,0.033534152521322066,0.0402724132402979,0.10756125519856213,0.04702122723017696])                                                                                                                                                                                                  |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.03633461261451775,0.05435343877060317,0.029667711217358537,0.043692779613046705,0.03842801475734904,0.05504489578214326,0.04323526359615616,0.040668124003502774,0.06014497474722926,0.05347218447408203,0.04078069115416455,0.05735262332007129,0.07916008937350884,0.09959551792685972,0.04354980585776841,0.025105111296864182,0.049692225770968906,0.04766745000978328,0.0562480250301968,0.04580646068382527])       |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.03944404162330052,0.04733666801310498,0.036270606882630244,0.044423818658652074,0.04709097596459405,0.049824819769256616,0.0477439145794566,0.04927055983463442,0.05692713608417113,0.057891249999380286,0.0458595619987104,0.05104345240764512,0.08542530794090919,0.07114825272540962,0.04164148475318913,0.02673723429449481,0.04690063981763621,0.04949748636861392,0.054828328941456304,0.050694459342754294])       |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.03133729925923136,0.05124612142454885,0.029419218080419845,0.04799985850115336,0.04201455061473651,0.054505675898521094,0.044824770584734656,0.03940779471315177,0.05894211622455923,0.06431109446393181,0.04462687268237287,0.06528913712039808,0.06746383345010842,0.08345500690116223,0.039003776071300365,0.026065572014814617,0.05938275649536728,0.04697262417525319,0.05150449119155595,0.05222743013267851])      |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.043197519419612175,0.04427358717138553,0.03838739702323422,0.04913528517349815,0.04967984618579301,0.061250527034667185,0.028680980732563418,0.038241151647085456,0.060304336035524445,0.04517928783107561,0.03684384860732483,0.0834402412631238,0.04739794708922429,0.08743653217058911,0.050753647722671005,0.025195120864347758,0.06414120409489209,0.0449095607395468,0.05147847337107657,0.05007350582276443])      |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.05035328447464929,0.05875530017194895,0.031391796597166295,0.04720178357656823,0.04628210795667487,0.051474964698449324,0.046386505599367224,0.04283626227347491,0.057656968694124226,0.044531045375392535,0.052616826347612014,0.05207503360125357,0.04897139452835449,0.08476079659520738,0.04464349751017888,0.03265383395184508,0.04480529357716353,0.05181232110280836,0.05988066461541847,0.05091031875234236])     |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.04409400273586092,0.06536117169338959,0.020157258393536423,0.04992818048870775,0.04946250830851103,0.05295413082135671,0.048415205322383276,0.024245506272955145,0.09826663466849005,0.019668677162218207,0.02415104263604847,0.1182895231767762,0.07855203452344132,0.034798428825462975,0.03631140399178746,0.03524770779898008,0.02771623029111258,0.0469022301560588,0.07071605996278583,0.05476206277013722])        |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.04029047258871348,0.04143195395865985,0.029471498315366735,0.045230033381296345,0.038211853910059344,0.05987770001832863,0.04182858778148341,0.04419595448629271,0.05708029587140727,0.06104215887231864,0.036701753791332684,0.059158439890455564,0.07485790188869995,0.10565931917256761,0.03450475446296726,0.030024749749364126,0.05646790110121782,0.0427172537490021,0.05004782623771851,0.051199590772748056])     |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.03515053270339997,0.05065680082494057,0.040032551134427746,0.0574573788034656,0.04654949264994538,0.07856417101698358,0.05276698053379494,0.028186454213147586,0.05858422117233328,0.05628477923604793,0.04503960379500859,0.03878676405623489,0.057758045018558836,0.08325456928665423,0.029314989185441634,0.025756966021789753,0.050772991682688846,0.04455878356187128,0.054806994303342536,0.0657169307999229])      |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.03733252723698539,0.047842338976585394,0.0292577350577866,0.049386875553271634,0.0380215951941978,0.05141893970364062,0.04480830063218707,0.04142627101067949,0.06633323973203886,0.051984830986021864,0.03998175729141533,0.058823474706450135,0.0750434564274028,0.09964831036113245,0.03595981876222591,0.028044987822971885,0.05039784084258555,0.04534846958355098,0.06220810679961904,0.046731123319251014])        |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "normalizer = Normalizer(inputCol=\"features\", outputCol=\"normFeatures\", p=1.0)\n",
    "l1NormData = normalizer.transform(tfidftweets)\n",
    "print(\"Normalized using L^1 norm\")\n",
    "l1NormData.select(\"normFeatures\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "def measures(tp,tn,fp,fn):\n",
    "    try: \n",
    "        precision = tp/(tp+fp)\n",
    "    except ZeroDivisionError as e: \n",
    "        precision = -1\n",
    "    \n",
    "    try:\n",
    "        recall = tp/(tp+fn)\n",
    "    except ZeroDivisionError as e: \n",
    "        recall = -1   \n",
    "    \n",
    "    try:\n",
    "        specificity = tn/(tn+fp)\n",
    "    except ZeroDivisionError as e: \n",
    "        specificity = -1\n",
    "    \n",
    "    try:\n",
    "        accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    except ZeroDivisionError as e: \n",
    "        accuracy = -1\n",
    "    \n",
    "    try:\n",
    "        f1_score = (2*tp)/((2*tp)+fp+fn)\n",
    "    except ZeroDivisionError as e: \n",
    "        f1_score = -1\n",
    "    return precision, recall, specificity, accuracy, f1_score\n",
    "\n",
    "def howgoodisit(result):\n",
    "    true_positives = result.filter(lambda line: line[1]==0.0 and line[0]==0.0).count()\n",
    "    true_negatives = result.filter(lambda line: line[1]==1.0 and line[0]==1.0).count()\n",
    "    false_positives = result.filter(lambda line: line[1]==0.0 and line[0]==1.0).count()\n",
    "    false_negatives = result.filter(lambda line: line[1]==1.0 and line[0]==0.0).count()\n",
    "    return measures(true_positives, true_negatives, false_positives, false_negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating NormFeatures and TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splits = l1NormData.randomSplit([0.6, 0.4])\n",
    "training_df = splits[0]\n",
    "test_df = splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = (LogisticRegression()).setMaxIter(1000).setRegParam(0.01)\n",
    "\n",
    "lr_pipeline = Pipeline(stages=[lr])\n",
    "\n",
    "lr_paramGrid = ParamGridBuilder().addGrid(lr.regParam, [0.01, 0.1, 0.5,1.0, 2.0]).build()\n",
    "\n",
    "lr_cv = CrossValidator(estimator=lr_pipeline, \n",
    "                    estimatorParamMaps=lr_paramGrid, \n",
    "                    evaluator=MulticlassClassificationEvaluator(), \n",
    "                    numFolds=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainData = training_df.select(\"label\", \"features\")\n",
    "testData = test_df.select(\"label\", \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_cvModel1 = lr_cv.fit(trainData)\n",
    "lr_result1 = lr_cvModel1.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6395348837209303"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "lr_evaluator.evaluate(lr_result1, {lr_evaluator.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.65811965812\n",
      "recall:  0.592307692308\n",
      "specificity:  0.6875\n",
      "accuracy:  0.639534883721\n",
      "f1_score:  0.623481781377\n"
     ]
    }
   ],
   "source": [
    "result = lr_result1.select(\"label\", \"prediction\").rdd.map(list)\n",
    "\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "\n",
    "print \"precision: \", precision\n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity\n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating L1 Norm features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L1trainData = training_df.selectExpr(\"label\", \"normFeatures as features\")\n",
    "L1testData = test_df.selectExpr(\"label\", \"normFeatures as features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_cvModel2 = lr_cv.fit(L1trainData)\n",
    "lr_result2 = lr_cvModel2.transform(L1testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6124031007751938"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_evaluator_norm = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "lr_evaluator_norm.evaluate(lr_result2, {lr_evaluator_norm.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.644230769231\n",
      "recall:  0.515384615385\n",
      "specificity:  0.7109375\n",
      "accuracy:  0.612403100775\n",
      "f1_score:  0.57264957265\n"
     ]
    }
   ],
   "source": [
    "result = lr_result2.select(\"label\", \"prediction\").rdd.map(list)\n",
    "\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "\n",
    "print \"precision: \", precision\n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity\n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb = NaiveBayes()\n",
    "pipeline = Pipeline(stages=[nb])\n",
    "paramGrid = ParamGridBuilder().addGrid(nb.smoothing, [0.0, 1.0]).build()\n",
    "\n",
    "\n",
    "cv = CrossValidator(estimator=pipeline, \n",
    "                    estimatorParamMaps=paramGrid, \n",
    "                    evaluator=MulticlassClassificationEvaluator(), \n",
    "                    numFolds=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_model1 = cv.fit(trainData)\n",
    "nb_result = nb_model1.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5038759689922481"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_evaluator_1 = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "nb_evaluator_1.evaluate(nb_result, {nb_evaluator_1.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.50495049505\n",
      "recall:  0.784615384615\n",
      "specificity:  0.21875\n",
      "accuracy:  0.503875968992\n",
      "f1_score:  0.614457831325\n"
     ]
    }
   ],
   "source": [
    "result = nb_result.select(\"label\", \"prediction\").rdd.map(list)\n",
    "\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "\n",
    "print \"precision: \", precision\n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity\n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating L1-Norm Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_model2 = cv.fit(L1trainData)\n",
    "nb_result_2 = nb_model2.transform(L1testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.562015503875969"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_evaluator_2 = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "nb_evaluator_2.evaluate(nb_result_2, {nb_evaluator_2.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  1.0\n",
      "recall:  0.130769230769\n",
      "specificity:  1.0\n",
      "accuracy:  0.562015503876\n",
      "f1_score:  0.231292517007\n"
     ]
    }
   ],
   "source": [
    "result = nb_result_2.select(\"label\", \"prediction\").rdd.map(list)\n",
    "\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "\n",
    "print \"precision: \", precision\n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity\n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "dt_pipeline = Pipeline(stages=[dt])\n",
    "dt_paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(dt.maxDepth, [1,2,6,10])\n",
    "             .addGrid(dt.maxBins, [20,40,80])\n",
    "             .build())\n",
    "\n",
    "dt_cv = CrossValidator(estimator=dt_pipeline, \n",
    "                    estimatorParamMaps=dt_paramGrid, \n",
    "                    evaluator=MulticlassClassificationEvaluator(), \n",
    "                    numFolds=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_model_1 = dt_cv.fit(trainData)\n",
    "dt_result_1 = dt_model_1.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6162790697674418"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_evaluator_1 = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "dt_evaluator_1.evaluate(dt_result_1, {dt_evaluator_1.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.701298701299\n",
      "recall:  0.415384615385\n",
      "specificity:  0.8203125\n",
      "accuracy:  0.616279069767\n",
      "f1_score:  0.521739130435\n"
     ]
    }
   ],
   "source": [
    "result = dt_result_1.select(\"label\", \"prediction\").rdd.map(list)\n",
    "\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "\n",
    "print \"precision: \", precision\n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity\n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating L1-Norm features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_model_2 = dt_cv.fit(L1trainData)\n",
    "dt_result_2 = dt_model_2.transform(L1testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6124031007751938"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_evaluator_2 = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "dt_evaluator_2.evaluate(dt_result_2, {dt_evaluator_2.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.678571428571\n",
      "recall:  0.438461538462\n",
      "specificity:  0.7890625\n",
      "accuracy:  0.612403100775\n",
      "f1_score:  0.532710280374\n"
     ]
    }
   ],
   "source": [
    "result = dt_result_2.select(\"label\", \"prediction\").rdd.map(list)\n",
    "\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "\n",
    "print \"precision: \", precision\n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity\n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers = [20, 5, 4, 2]\n",
    "\n",
    "mlp = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "\n",
    "mlp_pipeline = Pipeline(stages=[mlp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp_model_1 = mlp_pipeline.fit(trainData)\n",
    "mlp_result_1 = mlp_model_1.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6434108527131783"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "mlp_evaluator.evaluate(mlp_result_1, {mlp_evaluator.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.88\n",
      "recall:  0.338461538462\n",
      "specificity:  0.953125\n",
      "accuracy:  0.643410852713\n",
      "f1_score:  0.488888888889\n"
     ]
    }
   ],
   "source": [
    "result = mlp_result_1.select(\"label\", \"prediction\").rdd.map(list)\n",
    "\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "\n",
    "print \"precision: \", precision\n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity\n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating L1-Norm Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp_model_2 = mlp_pipeline.fit(L1trainData)\n",
    "mlp_result_2 = mlp_model_2.transform(L1testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.627906976744186"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_evaluator_2 = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "mlp_evaluator_2.evaluate(mlp_result_2, {mlp_evaluator_2.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.72972972973\n",
      "recall:  0.415384615385\n",
      "specificity:  0.84375\n",
      "accuracy:  0.627906976744\n",
      "f1_score:  0.529411764706\n"
     ]
    }
   ],
   "source": [
    "result = mlp_result_2.select(\"label\", \"prediction\").rdd.map(list)\n",
    "\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "\n",
    "print \"precision: \", precision\n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity\n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sgd import learn_coefficients\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the different classifier outputs to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-0.8437330355307...|[0.30074914654175...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[0.93868944850744...|[0.71883485612439...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[0.32067754762303...|[0.57948936681598...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[0.13720130338945...|[0.53424662059814...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-0.9003932513255...|[0.28896969081117...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[0.22174876564397...|[0.55521113739957...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-1.2276253652736...|[0.22659731256865...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[0.12983556453539...|[0.53241337049971...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[1.74955748884830...|[0.85189697968659...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[2.24583567409823...|[0.90429072311059...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[0.41562016201095...|[0.60243471954249...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-0.3254478208039...|[0.41934864895502...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[0.59460591052176...|[0.64442125619817...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[0.09176965488295...|[0.52292632615009...|       0.0|\n",
      "|    0|(20,[0,1,2,4,5,6,...|[0.39051155121645...|[0.59640583877015...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[0.26567308837670...|[0.56603034766213...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-0.8524306251117...|[0.29892322713619...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-1.0861202959333...|[0.25234955574217...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-0.2439991842304...|[0.43930105125452...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-0.5774759789022...|[0.35951357744159...|       1.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_result1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-1113.6828096638...|[0.89742907694073...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-1238.7627047954...|[0.99882790974169...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-1000.4753511161...|[0.97429750768652...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-1386.7957326956...|[0.99971642792676...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-1635.2350209786...|[0.99235526976524...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-672.62129385577...|[0.96186675165198...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-1593.0010655531...|[0.87088902658618...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-993.18881245899...|[0.99447778678775...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-1169.9255560422...|[0.95191204764108...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-950.28887457677...|[0.99998623396475...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-226.87913735120...|[0.82839699584481...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-920.59390605512...|[0.80150157205091...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-24.268363448165...|[0.52453816293513...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-687.68091891847...|[0.29516758946940...|       1.0|\n",
      "|    0|(20,[0,1,2,4,5,6,...|[-212.17381640833...|[0.88437517863641...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-1486.2570100371...|[0.98828916795826...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-969.97150579439...|[0.53442624317012...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-1096.4992198622...|[0.01229212637734...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-1605.2820725916...|[0.99776865020556...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-1315.8533821191...|[0.99518385286671...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-------------+--------------------+----------+\n",
      "|label|            features|rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+-------------+--------------------+----------+\n",
      "|    0|(20,[0,1,2,3,4,5,...|    [2.0,3.0]|           [0.4,0.6]|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|   [11.0,0.0]|           [1.0,0.0]|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|   [21.0,0.0]|           [1.0,0.0]|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|   [0.0,20.0]|           [0.0,1.0]|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|    [5.0,6.0]|[0.45454545454545...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|  [70.0,89.0]|[0.44025157232704...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|   [12.0,0.0]|           [1.0,0.0]|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|  [11.0,12.0]|[0.47826086956521...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|   [21.0,0.0]|           [1.0,0.0]|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|   [21.0,0.0]|           [1.0,0.0]|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|  [70.0,89.0]|[0.44025157232704...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|  [70.0,89.0]|[0.44025157232704...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|   [23.0,0.0]|           [1.0,0.0]|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|  [70.0,89.0]|[0.44025157232704...|       1.0|\n",
      "|    0|(20,[0,1,2,4,5,6,...|  [70.0,89.0]|[0.44025157232704...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|    [5.0,6.0]|[0.45454545454545...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|   [12.0,1.0]|[0.92307692307692...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|   [12.0,1.0]|[0.92307692307692...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|   [12.0,0.0]|           [1.0,0.0]|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|   [0.0,20.0]|           [0.0,1.0]|       1.0|\n",
      "+-----+--------------------+-------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_result_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+----------+\n",
      "|label|            features|prediction|\n",
      "+-----+--------------------+----------+\n",
      "|    0|(20,[0,1,2,3,4,5,...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       1.0|\n",
      "|    0|(20,[0,1,2,4,5,6,...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       1.0|\n",
      "+-----+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp_result_1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Combination of Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_column = lr_result1.select(\"label\").collect()\n",
    "lr_column = lr_result1.select(\"prediction\").collect()\n",
    "mlp_column = mlp_result_1.select(\"prediction\").collect()\n",
    "nb_column = nb_result.select(\"prediction\").collect()\n",
    "dt_column = dt_result_1.select(\"prediction\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp_label = [i[0] for i in label_column]\n",
    "temp_lr = [i[0] for i in lr_column]\n",
    "temp_mlp = [i[0] for i in mlp_column]\n",
    "temp_nb = [i[0] for i in nb_column]\n",
    "temp_dt = [i[0] for i in dt_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array([temp_lr,temp_mlp, temp_nb, temp_dt]).transpose()\n",
    "y = np.array([temp_label]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learned_weights = learn_coefficients(X, y, 0.001, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned Weights for(without using normalized features):\n",
      "Logistic Regression -0.34352507371\n",
      "Multilayer Perceptron 0.531763045663\n",
      "Naive Bayes -0.00615466342636\n",
      "Decision Tree 0.817916691474\n"
     ]
    }
   ],
   "source": [
    "print \"Learned Weights for(without using normalized features):\"\n",
    "print \"Logistic Regression\", learned_weights[0]/sum(learned_weights)\n",
    "print \"Multilayer Perceptron\", learned_weights[1]/sum(learned_weights)\n",
    "print \"Naive Bayes\", learned_weights[2]/sum(learned_weights)\n",
    "print \"Decision Tree\", learned_weights[3]/sum(learned_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining the classifier outputs with the help of another classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Using sklearn SVM here as Spark doesn't support SVM with RBF\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_rbf = svm.SVC()\n",
    "svm_rbf.fit(X,np.ravel(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_rbf_predictions = svm_rbf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.64238410596\n",
      "recall:  0.7578125\n",
      "specificity:  0.584615384615\n",
      "accuracy:  0.670542635659\n",
      "f1_score:  0.695340501792\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y, svm_rbf_predictions).ravel()\n",
    "\n",
    "precision, recall, specificity, accuracy, f1_score = measures(tp,tn,fp,fn)\n",
    "\n",
    "print \"precision: \", precision\n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity\n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combination of classifiers with logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_lr = linear_model.LogisticRegression(solver='lbfgs')\n",
    "meta_lr.fit(X, np.ravel(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_lr_predictions = meta_lr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.596590909091\n",
      "recall:  0.8203125\n",
      "specificity:  0.453846153846\n",
      "accuracy:  0.635658914729\n",
      "f1_score:  0.690789473684\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y, meta_lr_predictions).ravel()\n",
    "\n",
    "precision, recall, specificity, accuracy, f1_score = measures(tp,tn,fp,fn)\n",
    "\n",
    "print \"precision: \", precision\n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity\n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned Weights for classifiers using logistic regression as the meta-classifier:\n",
      "Logistic Regression 0.260974306538\n",
      "Multilayer Perceptron 0.595458210065\n",
      "Naive Bayes -0.0721486597383\n",
      "Decision Tree 0.215716143136\n"
     ]
    }
   ],
   "source": [
    "meta_learned_weights = meta_lr.coef_\n",
    "\n",
    "print \"Learned Weights for classifiers using logistic regression as the meta-classifier:\"\n",
    "print \"Logistic Regression\", meta_learned_weights[0][0]/sum(meta_learned_weights[0])\n",
    "print \"Multilayer Perceptron\", meta_learned_weights[0][1]/sum(meta_learned_weights[0])\n",
    "print \"Naive Bayes\", meta_learned_weights[0][2]/sum(meta_learned_weights[0])\n",
    "print \"Decision Tree\", meta_learned_weights[0][3]/sum(meta_learned_weights[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Using User Specific Features with the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_user_data(username): \n",
    "    conn = create_connection(\"../twitterApp/twitter.sqlite\")\n",
    "    sql = '''select num_status, num_friends, num_followers, isDepressed from users where user_screen_name=?'''\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql,(username,))\n",
    "    \n",
    "    a = cur.fetchall()\n",
    "    \n",
    "    return [a[0][0], a[0][1], a[0][2], a[0][3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_users = (trueNegatives + truePositives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userRDD = sc.parallelize(all_users).map(lambda line: line[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'PopoffSierra',\n",
       " u'dhenwikan',\n",
       " u'JosephineAlice',\n",
       " u'JoseJaimes95',\n",
       " u'lyriczbot']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userDataRDD = userRDD.map(lambda line : [str(line), fetch_user_data(str(line))])\\\n",
    "                     .map(lambda line: [line[0], line[1][:3], line[1][-1]])\\\n",
    "                     .map(lambda line: [line[0], Vectors.dense(line[1]), line[2]])\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['PopoffSierra', DenseVector([602.0, 100.0, 22.0]), 0],\n",
       " ['dhenwikan', DenseVector([935.0, 241.0, 234.0]), 0],\n",
       " ['JosephineAlice', DenseVector([50516.0, 828.0, 2066.0]), 0],\n",
       " ['JoseJaimes95', DenseVector([11049.0, 279.0, 360.0]), 0],\n",
       " ['lyriczbot', DenseVector([89519.0, 5.0, 20.0]), 0],\n",
       " ['grillmeeting1', DenseVector([99.0, 90.0, 4.0]), 0],\n",
       " ['bustercalamity1', DenseVector([99.0, 104.0, 5.0]), 0],\n",
       " ['_Coopavelli', DenseVector([223653.0, 2309.0, 3683.0]), 0],\n",
       " ['LeahEbooks', DenseVector([10578.0, 1.0, 28.0]), 0],\n",
       " ['KeyOfConceit', DenseVector([90.0, 206.0, 1571.0]), 0]]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userDataRDD.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user: string (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- label: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userDataDF = spark.createDataFrame(userDataRDD, [\"user\",\"features\", \"label\"])\n",
    "userDataDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+-----+--------------------+\n",
      "|           user|            features|label|      scaledFeatures|\n",
      "+---------------+--------------------+-----+--------------------+\n",
      "|   PopoffSierra|  [602.0,100.0,22.0]|    0|[-0.5511433475228...|\n",
      "|      dhenwikan| [935.0,241.0,234.0]|    0|[-0.5434584724786...|\n",
      "| JosephineAlice|[50516.0,828.0,20...|    0|[0.60075711180434...|\n",
      "|   JoseJaimes95|[11049.0,279.0,36...|    0|[-0.3100505860012...|\n",
      "|      lyriczbot|  [89519.0,5.0,20.0]|    0|[1.50085675549429...|\n",
      "|  grillmeeting1|     [99.0,90.0,4.0]|    0|[-0.5627514320490...|\n",
      "|bustercalamity1|    [99.0,104.0,5.0]|    0|[-0.5627514320490...|\n",
      "|    _Coopavelli|[223653.0,2309.0,...|    0|[4.59636134762072...|\n",
      "|     LeahEbooks|  [10578.0,1.0,28.0]|    0|[-0.3209201840367...|\n",
      "|   KeyOfConceit| [90.0,206.0,1571.0]|    0|[-0.5629591313746...|\n",
      "| goofy_goober33|      [1.0,25.0,2.0]|    0|[-0.5650130469269...|\n",
      "|      kalenstar|[28756.0,500.0,79...|    0|[0.09858629810557...|\n",
      "|        VBMagz4|[3040.0,601.0,286.0]|    0|[-0.4948799080101...|\n",
      "|   lizkennedyyy|[5195.0,761.0,125...|    0|[-0.4451474583997...|\n",
      "|       BRick441|[8796.0,1214.0,42...|    0|[-0.3620446504894...|\n",
      "|    Hello_Davey|[79458.0,1307.0,1...|    0|[1.26867198726711...|\n",
      "|mangledindustr1|   [121.0,119.0,5.0]|    0|[-0.5622437225867...|\n",
      "|  travisworland|[23909.0,1326.0,1...|    0|[-0.0132713275377...|\n",
      "|    PuffyPanda2|     [68.0,21.0,5.0]|    0|[-0.5634668408369...|\n",
      "|     thottinsos|[5747.0,2971.0,33...|    0|[-0.4324085664346...|\n",
      "+---------------+--------------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n",
    "                        withStd=True, withMean=True)\n",
    "scalerModel = scaler.fit(userDataDF)\n",
    "scaledData = scalerModel.transform(userDataDF)\n",
    "scaledData.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userSplits = scaledData.randomSplit([0.6, 0.4])\n",
    "userTraindf = userSplits[0]\n",
    "userTestdf = userSplits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userTrainData = userTraindf.select(\"label\", \"features\")\n",
    "userTestData = userTestdf.select(\"label\", \"features\")\n",
    "userTrainDataScaled = userTraindf.selectExpr(\"label\", \"scaledFeatures as features\")\n",
    "userTestDataScaled = userTestdf.selectExpr(\"label\", \"scaledFeatures as features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating unscaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_cvModel_3 = lr_cv.fit(userTrainData)\n",
    "lr_result_3 = lr_cvModel_3.transform(userTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_evaluator_3 = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "lr_evaluator_3.evaluate(lr_result_3, {lr_evaluator_3.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.490476190476\n",
      "recall:  0.792307692308\n",
      "specificity:  0.224637681159\n",
      "accuracy:  0.5\n",
      "f1_score:  0.605882352941\n"
     ]
    }
   ],
   "source": [
    "result = lr_result_3.select(\"label\", \"prediction\").rdd.map(list)\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "print \"precision: \", precision \n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity \n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Scaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_cvModel_4 = lr_cv.fit(userTrainDataScaled)\n",
    "lr_result_4 = lr_cvModel_4.transform(userTestDataScaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_evaluator_4 = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "lr_evaluator_4.evaluate(lr_result_4, {lr_evaluator_4.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.490476190476\n",
      "recall:  0.792307692308\n",
      "specificity:  0.224637681159\n",
      "accuracy:  0.5\n",
      "f1_score:  0.605882352941\n"
     ]
    }
   ],
   "source": [
    "result = lr_result_4.select(\"label\", \"prediction\").rdd.map(list)\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "print \"precision: \", precision \n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity \n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating unscaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_model_3 = cv.fit(userTrainData)\n",
    "nb_result_3 = nb_model_3.transform(userTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5111940298507462"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_evaluator_3 = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "nb_evaluator_3.evaluate(nb_result_3, {nb_evaluator_3.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.497942386831\n",
      "recall:  0.930769230769\n",
      "specificity:  0.115942028986\n",
      "accuracy:  0.511194029851\n",
      "f1_score:  0.648793565684\n"
     ]
    }
   ],
   "source": [
    "result = nb_result_3.select(\"label\", \"prediction\").rdd.map(list)\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "print \"precision: \", precision \n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity \n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Scaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_model_4 = cv.fit(userTrainDataScaled)\n",
    "nb_result_4 = nb_model_4.transform(userTestDataScaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5111940298507462"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_evaluator_4 = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "nb_evaluator_4.evaluate(nb_result_4, {nb_evaluator_4.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.497942386831\n",
      "recall:  0.930769230769\n",
      "specificity:  0.115942028986\n",
      "accuracy:  0.511194029851\n",
      "f1_score:  0.648793565684\n"
     ]
    }
   ],
   "source": [
    "result = nb_result_4.select(\"label\", \"prediction\").rdd.map(list)\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "print \"precision: \", precision \n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity \n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers_2 = [3, 5, 4, 2]\n",
    "\n",
    "mlp_2 = MultilayerPerceptronClassifier(maxIter=100, layers=layers_2, blockSize=128, seed=1234)\n",
    "\n",
    "mlp_pipeline_2 = Pipeline(stages=[mlp_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating unscaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp_model_3 = mlp_pipeline_2.fit(userTrainData)\n",
    "mlp_result_3 = mlp_model_3.transform(userTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6119402985074627"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_evaluator_3 = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "mlp_evaluator_3.evaluate(mlp_result_3, {mlp_evaluator_3.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.691176470588\n",
      "recall:  0.361538461538\n",
      "specificity:  0.847826086957\n",
      "accuracy:  0.611940298507\n",
      "f1_score:  0.474747474747\n"
     ]
    }
   ],
   "source": [
    "result = mlp_result_3.select(\"label\", \"prediction\").rdd.map(list)\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "print \"precision: \", precision \n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity \n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Scaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp_model_4 = mlp_pipeline_2.fit(userTrainDataScaled)\n",
    "mlp_result_4 = mlp_model_4.transform(userTestDataScaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.585820895522388"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_evaluator_4 = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "mlp_evaluator_4.evaluate(mlp_result_4, {mlp_evaluator_4.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.569343065693\n",
      "recall:  0.6\n",
      "specificity:  0.572463768116\n",
      "accuracy:  0.585820895522\n",
      "f1_score:  0.584269662921\n"
     ]
    }
   ],
   "source": [
    "result = mlp_result_4.select(\"label\", \"prediction\").rdd.map(list)\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "print \"precision: \", precision \n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity \n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating unscaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_model_3 = dt_cv.fit(userTrainData)\n",
    "dt_result_3 = dt_model_3.transform(userTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6492537313432836"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_evaluator_3 = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "dt_evaluator_3.evaluate(dt_result_3, {dt_evaluator_3.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.645161290323\n",
      "recall:  0.615384615385\n",
      "specificity:  0.68115942029\n",
      "accuracy:  0.649253731343\n",
      "f1_score:  0.629921259843\n"
     ]
    }
   ],
   "source": [
    "result = dt_result_3.select(\"label\", \"prediction\").rdd.map(list)\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "print \"precision: \", precision \n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity \n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating scaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_model_4 = dt_cv.fit(userTrainDataScaled)\n",
    "dt_result_4 = dt_model_4.transform(userTestDataScaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6492537313432836"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_evaluator_4 = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "dt_evaluator_4.evaluate(dt_result_4, {dt_evaluator_4.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.645161290323\n",
      "recall:  0.615384615385\n",
      "specificity:  0.68115942029\n",
      "accuracy:  0.649253731343\n",
      "f1_score:  0.629921259843\n"
     ]
    }
   ],
   "source": [
    "result = dt_result_4.select(\"label\", \"prediction\").rdd.map(list)\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "print \"precision: \", precision \n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity \n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Combination of classifiers through SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_column = lr_result_3.select(\"label\").collect()\n",
    "lr_column = lr_result_3.select(\"prediction\").collect()\n",
    "mlp_column = mlp_result_3.select(\"prediction\").collect()\n",
    "nb_column = nb_result_3.select(\"prediction\").collect()\n",
    "dt_column = dt_result_3.select(\"prediction\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp_label = [i[0] for i in label_column] \n",
    "temp_lr = [i[0] for i in lr_column]\n",
    "temp_mlp = [i[0] for i in mlp_column] \n",
    "temp_nb = [i[0] for i in nb_column] \n",
    "temp_dt = [i[0] for i in dt_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([temp_lr,temp_mlp, temp_nb, temp_dt]).transpose()\n",
    "y = np.array([temp_label]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learned_weights = learn_coefficients(X, y, 0.001, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned Weights for(without using normalized features):\n",
      "Logistic Regression -1.46949953889\n",
      "Multilayer Perceptron 0.306251618409\n",
      "Naive Bayes 0.387278623288\n",
      "Decision Tree 1.77596929719\n"
     ]
    }
   ],
   "source": [
    "print \"Learned Weights for(without using normalized features):\"\n",
    "print \"Logistic Regression\", learned_weights[0]/sum(learned_weights) \n",
    "print \"Multilayer Perceptron\", learned_weights[1]/sum(learned_weights) \n",
    "print \"Naive Bayes\", learned_weights[2]/sum(learned_weights)\n",
    "print \"Decision Tree\", learned_weights[3]/sum(learned_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_rbf.fit(X, np.ravel(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_rbf_predictions_2 = svm_rbf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.652777777778\n",
      "recall:  0.68115942029\n",
      "specificity:  0.615384615385\n",
      "accuracy:  0.649253731343\n",
      "f1_score:  0.666666666667\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y, svm_rbf_predictions_2).ravel()\n",
    "precision, recall, specificity, accuracy, f1_score = measures(tp,tn,fp,fn)\n",
    "print \"precision: \", precision \n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity \n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_lr_2 = linear_model.LogisticRegression(solver='lbfgs')\n",
    "meta_lr_2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_lr_predictions_2 = meta_lr_2.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.654411764706\n",
      "recall:  0.644927536232\n",
      "specificity:  0.638461538462\n",
      "accuracy:  0.641791044776\n",
      "f1_score:  0.649635036496\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y, meta_lr_predictions_2).ravel()\n",
    "precision, recall, specificity, accuracy, f1_score = measures(tp,tn,fp,fn)\n",
    "print \"precision: \", precision \n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity \n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_learned_weights_2 = meta_lr_2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned Weights for classifiers using logistic regression as the meta-classifier:\n",
      "Logistic Regression 0.260974306538\n",
      "Multilayer Perceptron 0.595458210065\n",
      "Naive Bayes -0.0721486597383\n",
      "Decision Tree 0.215716143136\n"
     ]
    }
   ],
   "source": [
    "print \"Learned Weights for classifiers using logistic regression as the meta-classifier:\"\n",
    "print \"Logistic Regression\", meta_learned_weights[0][0]/sum(meta_learned_weights[0])\n",
    "print \"Multilayer Perceptron\", meta_learned_weights[0][1]/sum(meta_learned_weights[0])\n",
    "print \"Naive Bayes\", meta_learned_weights[0][2]/sum(meta_learned_weights[0])\n",
    "print \"Decision Tree\", meta_learned_weights[0][3]/sum(meta_learned_weights[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Combining the user-specific and TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- username: string (nullable = true)\n",
      " |-- label: long (nullable = true)\n",
      " |-- tweet: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- rawFeatures: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- normFeatures: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "l1NormData.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user: string (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- label: long (nullable = true)\n",
      " |-- scaledFeatures: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaledData.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l1NormData.createOrReplaceTempView(\"tweetfeatures\")\n",
    "scaledData.createOrReplaceTempView(\"userfeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = spark.sql(\"select a.username, a.label, a.features as tweetfeatures, a.normFeatures, b.features as userfeatures, b.scaledFeatures from tweetfeatures as a, userfeatures as b where a.username=b.user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|       username|label|       tweetfeatures|        normFeatures|        userfeatures|      scaledFeatures|\n",
      "+---------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|    TeamGeekFam|    0|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|   [336.0,17.0,33.0]|[-0.5572820164771...|\n",
      "| ajrandomtweets|    0|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|[10418.0,203.0,25.0]|[-0.3246126164903...|\n",
      "|       seoulazy|    1|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|[32655.0,1542.0,5...|[0.18856626146088...|\n",
      "|     uV_Fanatic|    1|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|[14838.0,237.0,65...|[-0.2226091699578...|\n",
      "|       Dvnyells|    1|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|[20134.0,242.0,36...|[-0.1003896557414...|\n",
      "|     AxelLove21|    1|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|    [4587.0,0.0,0.0]|[-0.4591787017237...|\n",
      "|   polnareffbot|    0|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|  [6962.0,21.0,39.0]|[-0.4043691574896...|\n",
      "|      0Solstice|    0|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|[10167.0,775.0,12...|[-0.3304051199020...|\n",
      "|        NyjiBot|    1|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|    [3192.0,5.0,4.0]|[-0.4913720971791...|\n",
      "|   glitter__gal|    1|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|[20529.0,535.0,15...|[-0.0912739631214...|\n",
      "|    lindesaylou|    0|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|[10980.0,303.0,16...|[-0.3116429474968...|\n",
      "| morbidismyname|    1|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|      [8.0,22.0,6.0]|[-0.5648515030071...|\n",
      "|     caroabooth|    1|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|[10068.0,552.0,33...|[-0.3326898124827...|\n",
      "|       hannsimp|    1|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|[2830.0,5001.0,22...|[-0.4997262256055...|\n",
      "|      roseheels|    1|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...| [1514.0,54.0,134.0]|[-0.5300964825369...|\n",
      "|  LarryHarrisJr|    1|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|[9293.0,1233.0,64...|[-0.3505750321802...|\n",
      "|  ashleywrotenn|    0|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|[11879.0,927.0,19...|[-0.2908960926478...|\n",
      "|     aurorasuIt|    0|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|[26133.0,99.0,114...|[0.03805348356826...|\n",
      "|intranetshefei1|    0|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|  [115.0,141.0,12.0]|[-0.5623821888037...|\n",
      "|      spooksdun|    1|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|[41221.0,5932.0,1...|[0.38624986394910...|\n",
      "+---------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler_1 = VectorAssembler(\n",
    "    inputCols=[\"tweetfeatures\", \"userfeatures\"], outputCol=\"features\")\n",
    "assembler_2 = VectorAssembler(\n",
    "    inputCols=[\"normFeatures\", \"scaledFeatures\"], outputCol=\"standardizedfeatures\")\n",
    "\n",
    "assembling_pipeline = Pipeline(stages=[assembler_1, assembler_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combinedDataDF = assembler_2.transform(assembler_1.transform(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|       username|label|       tweetfeatures|        normFeatures|        userfeatures|      scaledFeatures|            features|standardizedfeatures|\n",
      "+---------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|    TeamGeekFam|    0|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|   [336.0,17.0,33.0]|[-0.5572820164771...|[3.22958828345280...|[0.05115337139413...|\n",
      "| ajrandomtweets|    0|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|[10418.0,203.0,25.0]|[-0.3246126164903...|[38.3270416771206...|[0.05686493046418...|\n",
      "|       seoulazy|    1|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|[32655.0,1542.0,5...|[0.18856626146088...|[10.7627002313619...|[0.04181716542838...|\n",
      "|     uV_Fanatic|    1|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|[14838.0,237.0,65...|[-0.2226091699578...|[11.8288534719235...|[0.03599261440994...|\n",
      "|       Dvnyells|    1|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|[20134.0,242.0,36...|[-0.1003896557414...|[11.5953892586618...|[0.03685052656085...|\n",
      "|     AxelLove21|    1|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|    [4587.0,0.0,0.0]|[-0.4591787017237...|[10.5370181585424...|[0.04166941084529...|\n",
      "|   polnareffbot|    0|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|  [6962.0,21.0,39.0]|[-0.4043691574896...|[18.6226620778374...|[0.05175624690008...|\n",
      "|      0Solstice|    0|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|[10167.0,775.0,12...|[-0.3304051199020...|[8.70821515465948...|[0.03315084398961...|\n",
      "|        NyjiBot|    1|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|    [3192.0,5.0,4.0]|[-0.4913720971791...|[0.14007852795698...|[0.00112124088597...|\n",
      "|   glitter__gal|    1|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|[20529.0,535.0,15...|[-0.0912739631214...|[14.7238097163679...|[0.03888623963096...|\n",
      "|    lindesaylou|    0|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|[10980.0,303.0,16...|[-0.3116429474968...|[12.2490890557944...|[0.03541779651146...|\n",
      "| morbidismyname|    1|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|      [8.0,22.0,6.0]|[-0.5648515030071...|[0.07003926397849...|[0.04914057860229...|\n",
      "|     caroabooth|    1|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|[10068.0,552.0,33...|[-0.3326898124827...|[17.5876373990441...|[0.04161667012305...|\n",
      "|       hannsimp|    1|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|[2830.0,5001.0,22...|[-0.4997262256055...|[19.2685797345280...|[0.04568954376882...|\n",
      "|      roseheels|    1|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...| [1514.0,54.0,134.0]|[-0.5300964825369...|[5.13621269175626...|[0.03632640461300...|\n",
      "|  LarryHarrisJr|    1|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|[9293.0,1233.0,64...|[-0.3505750321802...|[20.1090509022699...|[0.04402078854912...|\n",
      "|  ashleywrotenn|    0|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|[11879.0,927.0,19...|[-0.2908960926478...|[11.9378034381122...|[0.03575772768172...|\n",
      "|     aurorasuIt|    0|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|[26133.0,99.0,114...|[0.03805348356826...|[12.0311891234169...|[0.03967735297145...|\n",
      "|intranetshefei1|    0|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|  [115.0,141.0,12.0]|[-0.5623821888037...|[0.40467130298685...|[0.06706729210384...|\n",
      "|      spooksdun|    1|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|[41221.0,5932.0,1...|[0.38624986394910...|[12.1323569491636...|[0.03746407832972...|\n",
      "+---------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combinedDataDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#csvDatasetRDD = datasetRDD.map(lambda line: [line[0], line[1], line[2].values.tolist() + line[4].values.tolist(), line[3].values.tolist() + line[5].values.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#csvDatasetRDD.saveAsTextFile(\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#def toCSVLine(data):\n",
    "#    return ','.join(str(d) for d in data)\n",
    "\n",
    "#lines = csvDatasetRDD.map(toCSVLine).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#with open(\"dataset.csv\", \"a+\") as f: \n",
    "#    for line in lines: \n",
    "#        f.write(line+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from pyspark.ml.linalg import DenseVector, SparseVector\n",
    "#from pyspark.ml.linalg import Vectors\n",
    "#from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combinedDataRDD = csvDatasetRDD.map(lambda line: [line[0], line[1], Vectors.sparse(line[2]), Vectors.sparse(line[3])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#combinedDataDF = spark.createDataFrame(combinedDataRDD, [\"username\", \"label\", \"features\", \"normFeatures\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Combined Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_splits = combinedDataDF.randomSplit([0.6, 0.4])\n",
    "\n",
    "combinedTrainData = combined_splits[0].select(\"label\", \"features\")\n",
    "combinedTestData = combined_splits[1].select(\"label\", \"features\")\n",
    "combinedTrainDataScaled = combined_splits[0].selectExpr(\"label\", \"standardizedfeatures as features\")\n",
    "combinedTestDataScaled = combined_splits[1].selectExpr(\"label\", \"standardizedfeatures as features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    0|[3.22958828345280...|\n",
      "|    1|[10.7627002313619...|\n",
      "|    1|[0.14007852795698...|\n",
      "|    0|[12.2490890557944...|\n",
      "|    1|[0.07003926397849...|\n",
      "|    1|[17.5876373990441...|\n",
      "|    1|[19.2685797345280...|\n",
      "|    0|[11.9378034381122...|\n",
      "|    0|[0.40467130298685...|\n",
      "|    1|[12.1323569491636...|\n",
      "|    1|[11.2841036409796...|\n",
      "|    0|[8.80938298040620...|\n",
      "|    1|[1.70428875681003...|\n",
      "|    0|[5.43193402855435...|\n",
      "|    0|[1.48638882443249...|\n",
      "|    1|[21.3386290921146...|\n",
      "|    1|[2.38911711571086...|\n",
      "|    0|[0.44358200519713...|\n",
      "|    1|[16.6070877033452...|\n",
      "|    1|[1.57199236929509...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combinedTrainData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    0|[38.3270416771206...|\n",
      "|    1|[11.8288534719235...|\n",
      "|    1|[11.5953892586618...|\n",
      "|    1|[10.5370181585424...|\n",
      "|    0|[18.6226620778374...|\n",
      "|    0|[8.70821515465948...|\n",
      "|    1|[14.7238097163679...|\n",
      "|    1|[5.13621269175626...|\n",
      "|    1|[20.1090509022699...|\n",
      "|    0|[12.0311891234169...|\n",
      "|    1|[14.6615525928315...|\n",
      "|    1|[14.1712777449820...|\n",
      "|    1|[0.70039263978494...|\n",
      "|    1|[22.5370787201911...|\n",
      "|    0|[3.80546667616487...|\n",
      "|    0|[10.3113360857228...|\n",
      "|    1|[11.6265178204300...|\n",
      "|    0|[15.4086380752687...|\n",
      "|    0|[6.58369081397848...|\n",
      "|    1|[11.1128965512544...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combinedTestData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------------------------------------------------------+\n",
      "|label|features                                                         |\n",
      "+-----+-----------------------------------------------------------------+\n",
      "|0    |[-0.557282016477104,-0.20716859902950865,-0.131217318563865]     |\n",
      "|1    |[0.1885662614608838,0.05202307605378059,0.07912775883712071]     |\n",
      "|1    |[-0.4913720971791401,-0.20920814007934438,-0.1323081639223465]   |\n",
      "|0    |[-0.3116429474968774,-0.15855953734175735,-0.1262520914149147]   |\n",
      "|1    |[-0.5648515030071222,-0.20631879025874378,-0.13223293320796847]  |\n",
      "|1    |[-0.33268981248278184,-0.1162390605576662,-0.11989509604997076]  |\n",
      "|1    |[-0.4997262256055627,0.6399207836689266,-0.04646991881700864]    |\n",
      "|0    |[-0.29089609264783345,-0.052503402750299986,-0.12497316927048811]|\n",
      "|0    |[-0.562382188803732,-0.18609334151453957,-0.13200724106483439]   |\n",
      "|1    |[0.38624986394910443,0.7981551767853476,0.3085438223329383]      |\n",
      "|1    |[-0.06452690553518389,-0.10876074337493523,-0.10514987603187591] |\n",
      "|0    |[-0.5349428001324159,-0.1915321176474348,-0.12828332070312165]   |\n",
      "|1    |[-0.5560588982268266,-0.20240966991322532,-0.1314053953498101]   |\n",
      "|0    |[-0.5438738711297241,-0.20359940219229614,-0.13234577927953553]  |\n",
      "|0    |[-0.5530357191553864,-0.12609684229853885,-0.131217318563865]    |\n",
      "|1    |[1.7067560201919232,-0.10332196724203997,-0.10454803031685163]   |\n",
      "|1    |[-0.5255732527812348,-0.20563894324213186,-0.13148062606418814]  |\n",
      "|0    |[-0.5552742563304223,-0.2097180253418033,-0.1324586253511026]    |\n",
      "|1    |[-0.472586847071107,-0.16501808399957046,-0.08464950636386137]   |\n",
      "|1    |[-0.5543973036226763,-0.19187204115574077,-0.13023931927695057]  |\n",
      "+-----+-----------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combinedTrainDataScaled.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    0|[-0.3246126164903...|\n",
      "|    1|[-0.2226091699578...|\n",
      "|    1|[-0.1003896557414...|\n",
      "|    1|[-0.4591787017237...|\n",
      "|    0|[-0.4043691574896...|\n",
      "|    0|[-0.3304051199020...|\n",
      "|    1|[-0.0912739631214...|\n",
      "|    1|[-0.5300964825369...|\n",
      "|    1|[-0.3505750321802...|\n",
      "|    0|[0.03805348356826...|\n",
      "|    1|[3.87857555633060...|\n",
      "|    1|[-0.3564829241061...|\n",
      "|    1|[-0.5620360232612...|\n",
      "|    1|[1.29518826782501...|\n",
      "|    0|[-0.5474970704748...|\n",
      "|    0|[-0.3544520862565...|\n",
      "|    1|[0.25950711997696...|\n",
      "|    0|[-0.3902225256514...|\n",
      "|    0|[-0.5250655433188...|\n",
      "|    1|[0.21448252174506...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combinedTestDataScaled.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating unscaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_cvModel_5 = lr_cv.fit(combinedTrainData)\n",
    "lr_result_5 = lr_cvModel_5.transform(combinedTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6498054474708171"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_evaluator_5 = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "lr_evaluator_5.evaluate(lr_result_5, {lr_evaluator_5.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.63503649635\n",
      "recall:  0.685039370079\n",
      "specificity:  0.615384615385\n",
      "accuracy:  0.649805447471\n",
      "f1_score:  0.659090909091\n"
     ]
    }
   ],
   "source": [
    "result = lr_result_5.select(\"label\", \"prediction\").rdd.map(list)\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "print \"precision: \", precision \n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity \n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Scaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_cvModel_6 = lr_cv.fit(combinedTrainDataScaled)\n",
    "lr_result_6 = lr_cvModel_6.transform(combinedTestDataScaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6206896551724138"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_evaluator_6 = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "lr_evaluator_6.evaluate(lr_result_6, {lr_evaluator_6.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.603773584906\n",
      "recall:  0.581818181818\n",
      "specificity:  0.655737704918\n",
      "accuracy:  0.620689655172\n",
      "f1_score:  0.592592592593\n"
     ]
    }
   ],
   "source": [
    "result = lr_result_6.select(\"label\", \"prediction\").rdd.map(list)\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "print \"precision: \", precision \n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity \n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers_3 = [23, 5, 4, 2]\n",
    "\n",
    "mlp_3 = MultilayerPerceptronClassifier(maxIter=100, layers=layers_3, blockSize=128, seed=1234)\n",
    "\n",
    "mlp_pipeline_3 = Pipeline(stages=[mlp_3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating unscaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp_model_5 = mlp_pipeline_3.fit(combinedTrainData)\n",
    "mlp_result_5 = mlp_model_5.transform(combinedTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5408560311284046"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_evaluator_5 = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "mlp_evaluator_5.evaluate(mlp_result_5, {mlp_evaluator_5.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.8\n",
      "recall:  0.0944881889764\n",
      "specificity:  0.976923076923\n",
      "accuracy:  0.540856031128\n",
      "f1_score:  0.169014084507\n"
     ]
    }
   ],
   "source": [
    "result = mlp_result_5.select(\"label\", \"prediction\").rdd.map(list)\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "print \"precision: \", precision \n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity \n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Scaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp_model_6 = mlp_pipeline_3.fit(combinedTrainDataScaled)\n",
    "mlp_result_6 = mlp_model_6.transform(combinedTestDataScaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6120689655172413"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_evaluator_6 = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "mlp_evaluator_6.evaluate(mlp_result_6, {mlp_evaluator_6.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.590909090909\n",
      "recall:  0.590909090909\n",
      "specificity:  0.631147540984\n",
      "accuracy:  0.612068965517\n",
      "f1_score:  0.590909090909\n"
     ]
    }
   ],
   "source": [
    "result = mlp_result_6.select(\"label\", \"prediction\").rdd.map(list)\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "print \"precision: \", precision \n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity \n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating unscaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_model_5 = cv.fit(combinedTrainData)\n",
    "nb_result_5 = nb_model_5.transform(combinedTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5642023346303502"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_evaluator_5 = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "nb_evaluator_5.evaluate(nb_result_5, {nb_evaluator_5.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.549019607843\n",
      "recall:  0.661417322835\n",
      "specificity:  0.469230769231\n",
      "accuracy:  0.56420233463\n",
      "f1_score:  0.6\n"
     ]
    }
   ],
   "source": [
    "result = nb_result_5.select(\"label\", \"prediction\").rdd.map(list)\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "print \"precision: \", precision \n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity \n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Scaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_model_6 = cv.fit(combinedTrainDataScaled)\n",
    "nb_result_6 = nb_model_5.transform(combinedTestDataScaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_evaluator_6 = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "nb_evaluator_6.evaluate(nb_result_6, {nb_evaluator_6.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = nb_result_6.select(\"label\", \"prediction\").rdd.map(list)\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "print \"precision: \", precision \n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity \n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating unscaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_model_5 = dt_cv.fit(combinedTrainData)\n",
    "dt_result_5 = dt_model_5.transform(combinedTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5991379310344828"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_evaluator_5 = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "dt_evaluator_5.evaluate(dt_result_5, {dt_evaluator_5.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.571428571429\n",
      "recall:  0.618181818182\n",
      "specificity:  0.581967213115\n",
      "accuracy:  0.599137931034\n",
      "f1_score:  0.593886462882\n"
     ]
    }
   ],
   "source": [
    "result = dt_result_5.select(\"label\", \"prediction\").rdd.map(list)\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "print \"precision: \", precision \n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity \n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Scaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_model_6 = dt_cv.fit(combinedTrainDataScaled)\n",
    "dt_result_6 = dt_model_6.transform(combinedTestDataScaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6293103448275862"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_evaluator_6 = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "dt_evaluator_6.evaluate(dt_result_6, {dt_evaluator_6.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.571428571429\n",
      "recall:  0.618181818182\n",
      "specificity:  0.581967213115\n",
      "accuracy:  0.599137931034\n",
      "f1_score:  0.593886462882\n"
     ]
    }
   ],
   "source": [
    "result = dt_result_5.select(\"label\", \"prediction\").rdd.map(list)\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "print \"precision: \", precision \n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity \n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
