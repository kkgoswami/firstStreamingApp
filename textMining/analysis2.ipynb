{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from pyspark.context import SparkContext\n",
    "from os import path\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alltweets = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_connection(database):\n",
    "    try:\n",
    "        conn = sqlite3.connect(database)\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTweets(username): \n",
    "    sql = '''select tweet_text from tweets where user_screen_name=?'''\n",
    "    database = \"../twitterApp/twitter.sqlite\"\n",
    "    conn = create_connection(database)\n",
    "    \n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql,(username,))\n",
    "    \n",
    "    tweets = cur.fetchall()\n",
    "    \n",
    "    usertweets = []\n",
    "    \n",
    "    for tweet in tweets: \n",
    "        \n",
    "        usertweets.append((tweet[0]))\n",
    "    \n",
    "    #alltweets.extend(' '.join(usertweets))\n",
    "    \n",
    "    return usertweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTrueNegatives(database):\n",
    "    conn = create_connection(database)\n",
    "    sql = '''select user_screen_name from search_results where isDepressed=0 ORDER BY ROWID DESC LIMIT 322'''\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql)\n",
    "    users = cur.fetchall()\n",
    "    \n",
    "    return users\n",
    "    #for user in users: \n",
    "    #   user_tweets = getTweets(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTruePositives(database):    \n",
    "    conn = create_connection(database)\n",
    "    sql = '''select user_screen_name from search_results where isDepressed=\"True\"'''\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql)\n",
    "    users = cur.fetchall()\n",
    "    \n",
    "    return users\n",
    "    #for user in users: \n",
    "    #    user_tweets = getTweets(str(user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "\n",
    "def gettfidf(usertweets): \n",
    "    temp_df = spark.createDataFrame(usertweets,['tweet'])\n",
    "    tokenizer = Tokenizer(inputCol=\"tweet\", outputCol=\"words\")\n",
    "    wordsData = tokenizer.transform(temp_df)\n",
    "\n",
    "    hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=20)\n",
    "    featurizedData = hashingTF.transform(wordsData)\n",
    "    idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "    idfModel = idf.fit(featurizedData)\n",
    "    rescaledData = idfModel.transform(featurizedData)\n",
    "    \n",
    "    return rescaledData.select(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = getTruePositives(\"../twitterApp/twitter.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alltweets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_nonascii(text):\n",
    "    return ''.join([i if ord(i) < 128 else ' ' for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for user in test: \n",
    "    t = getTweets(user[0])    \n",
    "    alltweets.append(remove_nonascii(' '.join(t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the RDDs for users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trueNegatives = getTrueNegatives(\"../twitterApp/twitter.sqlite\")\n",
    "truePositives = getTruePositives(\"../twitterApp/twitter.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alltweets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for user in trueNegatives: \n",
    "    t = getTweets(user[0]) \n",
    "    alltweets.append([user[0], 0, remove_nonascii(' '.join(t))])\n",
    "\n",
    "for user in truePositives:\n",
    "    t = getTweets(user[0])\n",
    "    alltweets.append([user[0], 1, remove_nonascii(' '.join(t))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweetRDD = sc.parallelize(alltweets).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweetDF = tweetRDD.toDF([\"username\",\"label\",\"tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- username: string (nullable = true)\n",
      " |-- label: long (nullable = true)\n",
      " |-- tweet: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweetDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"tweet\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(tweetDF)\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=20)\n",
    "featurizedData = hashingTF.transform(wordsData)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "tfidftweets = idfModel.transform(featurizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|       username|label|               tweet|               words|         rawFeatures|            features|\n",
      "+---------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|   PopoffSierra|    0|RT @jacksfilms: \"...|[rt, @jacksfilms:...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|      dhenwikan|    0|Carnival and He -...|[carnival, and, h...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "| JosephineAlice|    0|Guess I'll just r...|[guess, i'll, jus...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|   JoseJaimes95|    0|Being able to mut...|[being, able, to,...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|      lyriczbot|    0|I miss that happy...|[i, miss, that, h...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|  grillmeeting1|    0|@1HkipUrdKrXXzdk ...|[@1hkipurdkrxxzdk...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|bustercalamity1|    0|@marcushegreat3 G...|[@marcushegreat3,...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|    _Coopavelli|    0|THE COOKOUT IS FR...|[the, cookout, is...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|     LeahEbooks|    0|?? the love good ...|[??, the, love, g...|(20,[0,1,2,4,5,6,...|(20,[0,1,2,4,5,6,...|\n",
      "|   KeyOfConceit|    0|@EthereaIVirago M...|[@ethereaivirago,...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "| goofy_goober33|    0|@Treyarch hey you...|[@treyarch, hey, ...|(20,[0,3,4,5,8,9,...|(20,[0,3,4,5,8,9,...|\n",
      "|      kalenstar|    0|gospel. let shit ...|[gospel., let, sh...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|        VBMagz4|    0|@EBJunkies coulda...|[@ebjunkies, coul...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|   lizkennedyyy|    0|RT @UberFacts: Re...|[rt, @uberfacts:,...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|       BRick441|    0|@Ian_height76 Hey...|[@ian_height76, h...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|    Hello_Davey|    0|@PRINCE_OF_NY For...|[@prince_of_ny, f...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|mangledindustr1|    0|@hleborezka1337 H...|[@hleborezka1337,...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|  travisworland|    0|What a day it has...|[what, a, day, it...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|    PuffyPanda2|    0|I should just mak...|[i, should, just,...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|     thottinsos|    0|@bizzleown ifb @A...|[@bizzleown, ifb,...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "+---------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidftweets.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized using L^1 norm\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|normFeatures                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.032591106549712826,0.08340048945781986,0.030010977281193896,0.05169725049954928,0.0413194205761345,0.05691590039224825,0.038161377340361284,0.07165100610495508,0.05608386252096416,0.05658973477395456,0.03725870605348249,0.05002066820424728,0.04276962486562839,0.10160059009848327,0.03620438363059918,0.027029534496298142,0.051466789093088175,0.04191228195073868,0.05313934799273264,0.04017694811780819])       |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.035531576354220364,0.07504515797872807,0.033661493388208764,0.03989061489087895,0.05057119630846068,0.07625203329007156,0.05603936247404978,0.051271327113606116,0.03490821536554983,0.054756018295254755,0.029928080741592415,0.0612629650802921,0.050185938664013434,0.08683962276513059,0.04470315556136033,0.030609863298618124,0.04390242391636751,0.03978366954264603,0.05141414418077494,0.053443140790175724])    |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.03593457569505255,0.048137332912243036,0.026537085665658933,0.05434921235597059,0.041780919515819255,0.05838640764634094,0.039209730017081765,0.04627580133996677,0.0691186665034533,0.07224132784738466,0.04219996678792248,0.05384853094324502,0.07275978556519638,0.07416817105415233,0.03596773985966315,0.023941104595599033,0.06308288022441189,0.047865232041133354,0.04852219946326612,0.04567332996643831])      |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.0350930201002845,0.050999597249113224,0.027673352993367206,0.041331728316347856,0.03848694623554719,0.05704561191513415,0.036665728397168015,0.049406390090078106,0.06489702074259754,0.06089882475161815,0.04506435203100827,0.055127900738559985,0.07469989098009065,0.08173025664885974,0.0374183090292938,0.028833997618119753,0.05464484558472872,0.056082308706013155,0.054833454908760404,0.04906646296330948])    |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.05495867978673711,0.052192964312467574,0.023192356977170033,0.05960837604747518,0.023797187205289443,0.08149127320979274,0.03784911107251535,0.05162944850080489,0.08819566568933969,0.07718180839332342,0.048006984548364405,0.05563251301572967,0.023312414845468435,0.06997581804447309,0.026404302871400116,0.03355200805293339,0.06838583382615133,0.04023344611441435,0.047714195667943486,0.03668561181820617])    |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.04560461444891344,0.0559530114921069,0.028502884030570903,0.04792224562363441,0.037968114941072544,0.0684603508909063,0.05305677194045238,0.04571169617538304,0.06555663327031307,0.03080715790090783,0.02732015848716392,0.13895815114336307,0.07746741738940371,0.03765319298999846,0.039364701762271116,0.05012597595784946,0.021377163022928174,0.03765319298999846,0.05256845060169049,0.037968114941072544])        |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.039613488419036794,0.06512243520938493,0.024587682466988357,0.03444964134258476,0.032561217604692466,0.06397790535051456,0.041011477788791384,0.037241961159475465,0.06146920616747089,0.041011477788791384,0.017184575616716335,0.1085248575415707,0.10700954594630144,0.04265193690034304,0.047573314234998006,0.039309629123131136,0.025953664826265488,0.057416068904307935,0.06353040433086991,0.049799509277764956])|\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.03523966369363943,0.05176896133310238,0.033015561496986166,0.04748457240305381,0.03700753059153503,0.05258916393638209,0.04798909598483626,0.037730078490200825,0.04752165026849132,0.050066546027469856,0.04352451956430687,0.049395946052505114,0.09480130907151589,0.10580156288555427,0.041163188701897266,0.025048564263947106,0.04828772991400521,0.049591700303439325,0.05564393928596844,0.04632871573116324])    |\n",
      "|(20,[0,1,2,4,5,6,8,9,10,12,13,14,15,16,17,18,19],[0.0556922631997938,0.13356055677577905,0.03635467181097651,0.01843817431127344,0.10775580582753995,0.010350927160773543,0.0556922631997938,0.08453257181298393,0.056201311034068335,0.0073315158482209295,0.06077852102095234,0.07378353206910372,0.011041439530453206,0.07834487025526549,0.05799173293920561,0.023392508307444534,0.12875733489637167])                                                                          |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.036573884081695845,0.05128350606153241,0.02767753389966172,0.055794005031382266,0.03187893620041204,0.06647796344164697,0.07478770887185282,0.058655617982482165,0.05930900121356082,0.04154872715102935,0.03316132026594191,0.060684773348696784,0.05452175232808903,0.06054243099149991,0.04867136609120581,0.03318715359101071,0.058320517860001475,0.046297153111146995,0.050729183119984575,0.049897465357166666])   |\n",
      "|(20,[0,3,4,5,8,9,10,15,16,17,18,19],[0.13413661008528827,0.0805448264805958,0.14106368169053088,0.1610896529611916,0.06706830504264413,0.0805448264805958,0.0803566369487923,0.026806412120002173,0.033534152521322066,0.0402724132402979,0.10756125519856213,0.04702122723017696])                                                                                                                                                                                                  |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.03633461261451775,0.05435343877060317,0.029667711217358537,0.043692779613046705,0.03842801475734904,0.05504489578214326,0.04323526359615616,0.040668124003502774,0.06014497474722926,0.05347218447408203,0.04078069115416455,0.05735262332007129,0.07916008937350884,0.09959551792685972,0.04354980585776841,0.025105111296864182,0.049692225770968906,0.04766745000978328,0.0562480250301968,0.04580646068382527])       |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.03944404162330052,0.04733666801310498,0.036270606882630244,0.044423818658652074,0.04709097596459405,0.049824819769256616,0.0477439145794566,0.04927055983463442,0.05692713608417113,0.057891249999380286,0.0458595619987104,0.05104345240764512,0.08542530794090919,0.07114825272540962,0.04164148475318913,0.02673723429449481,0.04690063981763621,0.04949748636861392,0.054828328941456304,0.050694459342754294])       |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.03133729925923136,0.05124612142454885,0.029419218080419845,0.04799985850115336,0.04201455061473651,0.054505675898521094,0.044824770584734656,0.03940779471315177,0.05894211622455923,0.06431109446393181,0.04462687268237287,0.06528913712039808,0.06746383345010842,0.08345500690116223,0.039003776071300365,0.026065572014814617,0.05938275649536728,0.04697262417525319,0.05150449119155595,0.05222743013267851])      |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.043197519419612175,0.04427358717138553,0.03838739702323422,0.04913528517349815,0.04967984618579301,0.061250527034667185,0.028680980732563418,0.038241151647085456,0.060304336035524445,0.04517928783107561,0.03684384860732483,0.0834402412631238,0.04739794708922429,0.08743653217058911,0.050753647722671005,0.025195120864347758,0.06414120409489209,0.0449095607395468,0.05147847337107657,0.05007350582276443])      |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.05035328447464929,0.05875530017194895,0.031391796597166295,0.04720178357656823,0.04628210795667487,0.051474964698449324,0.046386505599367224,0.04283626227347491,0.057656968694124226,0.044531045375392535,0.052616826347612014,0.05207503360125357,0.04897139452835449,0.08476079659520738,0.04464349751017888,0.03265383395184508,0.04480529357716353,0.05181232110280836,0.05988066461541847,0.05091031875234236])     |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.04409400273586092,0.06536117169338959,0.020157258393536423,0.04992818048870775,0.04946250830851103,0.05295413082135671,0.048415205322383276,0.024245506272955145,0.09826663466849005,0.019668677162218207,0.02415104263604847,0.1182895231767762,0.07855203452344132,0.034798428825462975,0.03631140399178746,0.03524770779898008,0.02771623029111258,0.0469022301560588,0.07071605996278583,0.05476206277013722])        |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.04029047258871348,0.04143195395865985,0.029471498315366735,0.045230033381296345,0.038211853910059344,0.05987770001832863,0.04182858778148341,0.04419595448629271,0.05708029587140727,0.06104215887231864,0.036701753791332684,0.059158439890455564,0.07485790188869995,0.10565931917256761,0.03450475446296726,0.030024749749364126,0.05646790110121782,0.0427172537490021,0.05004782623771851,0.051199590772748056])     |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.03515053270339997,0.05065680082494057,0.040032551134427746,0.0574573788034656,0.04654949264994538,0.07856417101698358,0.05276698053379494,0.028186454213147586,0.05858422117233328,0.05628477923604793,0.04503960379500859,0.03878676405623489,0.057758045018558836,0.08325456928665423,0.029314989185441634,0.025756966021789753,0.050772991682688846,0.04455878356187128,0.054806994303342536,0.0657169307999229])      |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.03733252723698539,0.047842338976585394,0.0292577350577866,0.049386875553271634,0.0380215951941978,0.05141893970364062,0.04480830063218707,0.04142627101067949,0.06633323973203886,0.051984830986021864,0.03998175729141533,0.058823474706450135,0.0750434564274028,0.09964831036113245,0.03595981876222591,0.028044987822971885,0.05039784084258555,0.04534846958355098,0.06220810679961904,0.046731123319251014])        |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "normalizer = Normalizer(inputCol=\"features\", outputCol=\"normFeatures\", p=1.0)\n",
    "l1NormData = normalizer.transform(tfidftweets)\n",
    "print(\"Normalized using L^1 norm\")\n",
    "l1NormData.select(\"normFeatures\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "def measures(tp,tn,fp,fn):\n",
    "    try: \n",
    "        precision = tp/(tp+fp)\n",
    "    except ZeroDivisionError as e: \n",
    "        precision = -1\n",
    "    \n",
    "    try:\n",
    "        recall = tp/(tp+fn)\n",
    "    except ZeroDivisionError as e: \n",
    "        recall = -1   \n",
    "    \n",
    "    try:\n",
    "        specificity = tn/(tn+fp)\n",
    "    except ZeroDivisionError as e: \n",
    "        specificity = -1\n",
    "    \n",
    "    try:\n",
    "        accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    except ZeroDivisionError as e: \n",
    "        accuracy = -1\n",
    "    \n",
    "    try:\n",
    "        f1_score = (2*tp)/((2*tp)+fp+fn)\n",
    "    except ZeroDivisionError as e: \n",
    "        f1_score = -1\n",
    "    return precision, recall, specificity, accuracy, f1_score\n",
    "\n",
    "def howgoodisit(result):\n",
    "    true_positives = result.filter(lambda line: line[1]==0.0 and line[0]==0.0).count()\n",
    "    true_negatives = result.filter(lambda line: line[1]==1.0 and line[0]==1.0).count()\n",
    "    false_positives = result.filter(lambda line: line[1]==0.0 and line[0]==1.0).count()\n",
    "    false_negatives = result.filter(lambda line: line[1]==1.0 and line[0]==0.0).count()\n",
    "    return measures(true_positives, true_negatives, false_positives, false_negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating NormFeatures and TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splits = l1NormData.randomSplit([0.6, 0.4])\n",
    "training_df = splits[0]\n",
    "test_df = splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = (LogisticRegression()).setMaxIter(1000).setRegParam(0.01)\n",
    "\n",
    "lr_pipeline = Pipeline(stages=[lr])\n",
    "\n",
    "lr_paramGrid = ParamGridBuilder().addGrid(lr.regParam, [0.01, 0.1, 0.5,1.0, 2.0]).build()\n",
    "\n",
    "lr_cv = CrossValidator(estimator=lr_pipeline, \n",
    "                    estimatorParamMaps=lr_paramGrid, \n",
    "                    evaluator=MulticlassClassificationEvaluator(), \n",
    "                    numFolds=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainData = training_df.select(\"label\", \"features\")\n",
    "testData = test_df.select(\"label\", \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_cvModel1 = lr_cv.fit(trainData)\n",
    "lr_result1 = lr_cvModel1.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6731517509727627"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "lr_evaluator.evaluate(lr_result1, {lr_evaluator.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.650793650794\n",
      "recall:  0.672131147541\n",
      "specificity:  0.674074074074\n",
      "accuracy:  0.673151750973\n",
      "f1_score:  0.661290322581\n"
     ]
    }
   ],
   "source": [
    "result = lr_result1.select(\"label\", \"prediction\").rdd.map(list)\n",
    "\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "\n",
    "print \"precision: \", precision\n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity\n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating L1 Norm features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L1trainData = training_df.selectExpr(\"label\", \"normFeatures as features\")\n",
    "L1testData = test_df.selectExpr(\"label\", \"normFeatures as features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_cvModel2 = lr_cv.fit(L1trainData)\n",
    "lr_result2 = lr_cvModel2.transform(L1testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6809338521400778"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_evaluator_norm = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "lr_evaluator_norm.evaluate(lr_result2, {lr_evaluator_norm.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.675438596491\n",
      "recall:  0.631147540984\n",
      "specificity:  0.725925925926\n",
      "accuracy:  0.68093385214\n",
      "f1_score:  0.652542372881\n"
     ]
    }
   ],
   "source": [
    "result = lr_result2.select(\"label\", \"prediction\").rdd.map(list)\n",
    "\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "\n",
    "print \"precision: \", precision\n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity\n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb = NaiveBayes()\n",
    "pipeline = Pipeline(stages=[nb])\n",
    "paramGrid = ParamGridBuilder().addGrid(nb.smoothing, [0.0, 1.0]).build()\n",
    "\n",
    "\n",
    "cv = CrossValidator(estimator=pipeline, \n",
    "                    estimatorParamMaps=paramGrid, \n",
    "                    evaluator=MulticlassClassificationEvaluator(), \n",
    "                    numFolds=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_model1 = cv.fit(trainData)\n",
    "nb_result = nb_model1.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48249027237354086"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_evaluator_1 = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "nb_evaluator_1.evaluate(nb_result, {nb_evaluator_1.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.475982532751\n",
      "recall:  0.893442622951\n",
      "specificity:  0.111111111111\n",
      "accuracy:  0.482490272374\n",
      "f1_score:  0.621082621083\n"
     ]
    }
   ],
   "source": [
    "result = nb_result.select(\"label\", \"prediction\").rdd.map(list)\n",
    "\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "\n",
    "print \"precision: \", precision\n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity\n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating L1-Norm Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_model2 = cv.fit(L1trainData)\n",
    "nb_result_2 = nb_model2.transform(L1testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47470817120622566"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_evaluator_2 = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "nb_evaluator_2.evaluate(nb_result_2, {nb_evaluator_2.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.474708171206\n",
      "recall:  1.0\n",
      "specificity:  0.0\n",
      "accuracy:  0.474708171206\n",
      "f1_score:  0.643799472296\n"
     ]
    }
   ],
   "source": [
    "result = nb_result_2.select(\"label\", \"prediction\").rdd.map(list)\n",
    "\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "\n",
    "print \"precision: \", precision\n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity\n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "dt_pipeline = Pipeline(stages=[dt])\n",
    "dt_paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(dt.maxDepth, [1,2,6,10])\n",
    "             .addGrid(dt.maxBins, [20,40,80])\n",
    "             .build())\n",
    "\n",
    "dt_cv = CrossValidator(estimator=dt_pipeline, \n",
    "                    estimatorParamMaps=dt_paramGrid, \n",
    "                    evaluator=MulticlassClassificationEvaluator(), \n",
    "                    numFolds=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_model_1 = dt_cv.fit(trainData)\n",
    "dt_result_1 = dt_model_1.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6108949416342413"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_evaluator_1 = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "dt_evaluator_1.evaluate(dt_result_1, {dt_evaluator_1.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.677419354839\n",
      "recall:  0.344262295082\n",
      "specificity:  0.851851851852\n",
      "accuracy:  0.610894941634\n",
      "f1_score:  0.45652173913\n"
     ]
    }
   ],
   "source": [
    "result = dt_result_1.select(\"label\", \"prediction\").rdd.map(list)\n",
    "\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "\n",
    "print \"precision: \", precision\n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity\n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating L1-Norm features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_model_2 = dt_cv.fit(L1trainData)\n",
    "dt_result_2 = dt_model_2.transform(L1testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6303501945525292"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_evaluator_2 = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "dt_evaluator_2.evaluate(dt_result_2, {dt_evaluator_2.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.619469026549\n",
      "recall:  0.573770491803\n",
      "specificity:  0.681481481481\n",
      "accuracy:  0.630350194553\n",
      "f1_score:  0.595744680851\n"
     ]
    }
   ],
   "source": [
    "result = dt_result_2.select(\"label\", \"prediction\").rdd.map(list)\n",
    "\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "\n",
    "print \"precision: \", precision\n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity\n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers = [20, 5, 4, 2]\n",
    "\n",
    "mlp = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "\n",
    "mlp_pipeline = Pipeline(stages=[mlp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp_model_1 = mlp_pipeline.fit(trainData)\n",
    "mlp_result_1 = mlp_model_1.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.669260700389105"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "mlp_evaluator.evaluate(mlp_result_1, {mlp_evaluator.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.803278688525\n",
      "recall:  0.401639344262\n",
      "specificity:  0.911111111111\n",
      "accuracy:  0.669260700389\n",
      "f1_score:  0.535519125683\n"
     ]
    }
   ],
   "source": [
    "result = mlp_result_1.select(\"label\", \"prediction\").rdd.map(list)\n",
    "\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "\n",
    "print \"precision: \", precision\n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity\n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating L1-Norm Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp_model_2 = mlp_pipeline.fit(L1trainData)\n",
    "mlp_result_2 = mlp_model_2.transform(L1testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6264591439688716"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_evaluator_2 = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "mlp_evaluator_2.evaluate(mlp_result_2, {mlp_evaluator_2.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.647727272727\n",
      "recall:  0.467213114754\n",
      "specificity:  0.77037037037\n",
      "accuracy:  0.626459143969\n",
      "f1_score:  0.542857142857\n"
     ]
    }
   ],
   "source": [
    "result = mlp_result_2.select(\"label\", \"prediction\").rdd.map(list)\n",
    "\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "\n",
    "print \"precision: \", precision\n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity\n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sgd import learn_coefficients\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the different classifier outputs to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|    0|(20,[0,1,2,3,4,5,...|[0.06515744216991...|[0.51628359995859...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[0.54663345557991...|[0.63335417484533...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[0.14942615375561...|[0.53728718467711...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[0.33136720281626...|[0.58209200111472...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[1.70106693253995...|[0.84567403107136...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[3.90337710723941...|[0.98022526136651...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[0.42617525181579...|[0.60495998500858...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-0.2387149948753...|[0.44060304430268...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[0.96388016388587...|[0.72389800560939...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[0.15644939812627...|[0.53903276681032...|       0.0|\n",
      "|    0|(20,[0,1,2,4,5,6,...|[0.52100147336779...|[0.62738191444653...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-0.8243890585700...|[0.30483277966288...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[0.54205558519665...|[0.63229046954531...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[1.18049935926156...|[0.76503757800855...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[0.56713836614738...|[0.63810260621744...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-1.1096044195068...|[0.24794464434745...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[0.03837332551639...|[0.50959215436102...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-0.3746665084005...|[0.40741391170784...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-0.0188330684238...|[0.49529187205153...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-0.4961076247361...|[0.37845582649592...|       1.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_result1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-715.95208727958...|[0.17736133564222...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-1391.4741301063...|[0.99998174046100...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-1592.6972640193...|[0.99651028125347...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-996.23488885688...|[0.99927959250167...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-1170.2822817213...|[0.99500349050029...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-955.26887608418...|[0.99999797299938...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-227.82468383076...|[0.89728979880548...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-921.53963071971...|[0.97025640607397...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-1074.1477689233...|[0.96677171461823...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-686.82063801379...|[0.68981663233118...|       0.0|\n",
      "|    0|(20,[0,1,2,4,5,6,...|[-213.34756487457...|[0.93346219241973...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-970.97822166686...|[0.92135034216348...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-372.77316668392...|[0.72858121338507...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-1126.4585688399...|[0.88534610472050...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-93.576996042933...|[0.72127758192834...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-1094.4784895895...|[0.15768306796373...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-1609.0737573911...|[0.99992669993398...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-904.51016072092...|[0.34227654318058...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-1125.1289128219...|[0.99740488466499...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-1097.3492567925...|[0.99974229716424...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-------------+--------------------+----------+\n",
      "|label|            features|rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+-------------+--------------------+----------+\n",
      "|    0|(20,[0,1,2,3,4,5,...|  [66.0,80.0]|[0.45205479452054...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|    [5.0,0.0]|           [1.0,0.0]|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|   [13.0,0.0]|           [1.0,0.0]|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|   [22.0,6.0]|[0.78571428571428...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|  [66.0,80.0]|[0.45205479452054...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|  [66.0,80.0]|[0.45205479452054...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|  [66.0,80.0]|[0.45205479452054...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|  [16.0,48.0]|         [0.25,0.75]|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|   [22.0,6.0]|[0.78571428571428...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|  [66.0,80.0]|[0.45205479452054...|       1.0|\n",
      "|    0|(20,[0,1,2,4,5,6,...|    [2.0,0.0]|           [1.0,0.0]|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|  [16.0,48.0]|         [0.25,0.75]|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|  [66.0,80.0]|[0.45205479452054...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|   [13.0,0.0]|           [1.0,0.0]|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|  [66.0,80.0]|[0.45205479452054...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|  [16.0,48.0]|         [0.25,0.75]|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|    [5.0,0.0]|           [1.0,0.0]|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|  [66.0,80.0]|[0.45205479452054...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|  [26.0,30.0]|[0.46428571428571...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|  [16.0,48.0]|         [0.25,0.75]|       1.0|\n",
      "+-----+--------------------+-------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_result_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+----------+\n",
      "|label|            features|prediction|\n",
      "+-----+--------------------+----------+\n",
      "|    0|(20,[0,1,2,3,4,5,...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       1.0|\n",
      "|    0|(20,[0,1,2,4,5,6,...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       1.0|\n",
      "+-----+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp_result_1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Combination of Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_column = lr_result1.select(\"label\").collect()\n",
    "lr_column = lr_result1.select(\"prediction\").collect()\n",
    "mlp_column = mlp_result_1.select(\"prediction\").collect()\n",
    "nb_column = nb_result.select(\"prediction\").collect()\n",
    "dt_column = dt_result_1.select(\"prediction\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp_label = [i[0] for i in label_column]\n",
    "temp_lr = [i[0] for i in lr_column]\n",
    "temp_mlp = [i[0] for i in mlp_column]\n",
    "temp_nb = [i[0] for i in nb_column]\n",
    "temp_dt = [i[0] for i in dt_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array([temp_lr,temp_mlp, temp_nb, temp_dt]).transpose()\n",
    "y = np.array([temp_label]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learned_weights = learn_coefficients(X, y, 0.001, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned Weights for(without using normalized features):\n",
      "Logistic Regression -0.992288006554\n",
      "Multilayer Perceptron 1.36996061338\n",
      "Naive Bayes 0.0815590240696\n",
      "Decision Tree 0.540768369103\n"
     ]
    }
   ],
   "source": [
    "print \"Learned Weights for(without using normalized features):\"\n",
    "print \"Logistic Regression\", learned_weights[0]/sum(learned_weights)\n",
    "print \"Multilayer Perceptron\", learned_weights[1]/sum(learned_weights)\n",
    "print \"Naive Bayes\", learned_weights[2]/sum(learned_weights)\n",
    "print \"Decision Tree\", learned_weights[3]/sum(learned_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining the classifier outputs with the help of another classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Using sklearn SVM here as Spark doesn't support SVM with RBF\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_rbf = svm.SVC()\n",
    "svm_rbf.fit(X,np.ravel(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_rbf_predictions = svm_rbf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.655555555556\n",
      "recall:  0.874074074074\n",
      "specificity:  0.491803278689\n",
      "accuracy:  0.692607003891\n",
      "f1_score:  0.749206349206\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y, svm_rbf_predictions).ravel()\n",
    "\n",
    "precision, recall, specificity, accuracy, f1_score = measures(tp,tn,fp,fn)\n",
    "\n",
    "print \"precision: \", precision\n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity\n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combination of classifiers with logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_lr = linear_model.LogisticRegression(solver='lbfgs')\n",
    "meta_lr.fit(X, np.ravel(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_lr_predictions = meta_lr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.655172413793\n",
      "recall:  0.844444444444\n",
      "specificity:  0.508196721311\n",
      "accuracy:  0.684824902724\n",
      "f1_score:  0.73786407767\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y, meta_lr_predictions).ravel()\n",
    "\n",
    "precision, recall, specificity, accuracy, f1_score = measures(tp,tn,fp,fn)\n",
    "\n",
    "print \"precision: \", precision\n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity\n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned Weights for classifiers using logistic regression as the meta-classifier:\n",
      "Logistic Regression 0.370843180805\n",
      "Multilayer Perceptron 0.532148078738\n",
      "Naive Bayes -0.134881083998\n",
      "Decision Tree 0.231889824455\n"
     ]
    }
   ],
   "source": [
    "meta_learned_weights = meta_lr.coef_\n",
    "\n",
    "print \"Learned Weights for classifiers using logistic regression as the meta-classifier:\"\n",
    "print \"Logistic Regression\", meta_learned_weights[0][0]/sum(meta_learned_weights[0])\n",
    "print \"Multilayer Perceptron\", meta_learned_weights[0][1]/sum(meta_learned_weights[0])\n",
    "print \"Naive Bayes\", meta_learned_weights[0][2]/sum(meta_learned_weights[0])\n",
    "print \"Decision Tree\", meta_learned_weights[0][3]/sum(meta_learned_weights[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Using User Specific Features with the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_user_data(username): \n",
    "    conn = create_connection(\"../twitterApp/twitter.sqlite\")\n",
    "    sql = '''select num_status, num_friends, num_followers, isDepressed from users where user_screen_name=?'''\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql,(username,))\n",
    "    \n",
    "    a = cur.fetchall()\n",
    "    \n",
    "    return [a[0][0], a[0][1], a[0][2], a[0][3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_users = (trueNegatives + truePositives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userRDD = sc.parallelize(all_users).map(lambda line: line[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'PopoffSierra',\n",
       " u'dhenwikan',\n",
       " u'JosephineAlice',\n",
       " u'JoseJaimes95',\n",
       " u'lyriczbot']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userDataRDD = userRDD.map(lambda line : [str(line), fetch_user_data(str(line))])\\\n",
    "                     .map(lambda line: [line[0], line[1][:3], line[1][-1]])\\\n",
    "                     .map(lambda line: [line[0], Vectors.dense(line[1]), line[2]])\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['PopoffSierra', DenseVector([602.0, 100.0, 22.0]), 0],\n",
       " ['dhenwikan', DenseVector([935.0, 241.0, 234.0]), 0],\n",
       " ['JosephineAlice', DenseVector([50516.0, 828.0, 2066.0]), 0],\n",
       " ['JoseJaimes95', DenseVector([11049.0, 279.0, 360.0]), 0],\n",
       " ['lyriczbot', DenseVector([89519.0, 5.0, 20.0]), 0],\n",
       " ['grillmeeting1', DenseVector([99.0, 90.0, 4.0]), 0],\n",
       " ['bustercalamity1', DenseVector([99.0, 104.0, 5.0]), 0],\n",
       " ['_Coopavelli', DenseVector([223653.0, 2309.0, 3683.0]), 0],\n",
       " ['LeahEbooks', DenseVector([10578.0, 1.0, 28.0]), 0],\n",
       " ['KeyOfConceit', DenseVector([90.0, 206.0, 1571.0]), 0]]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userDataRDD.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user: string (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- label: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userDataDF = spark.createDataFrame(userDataRDD, [\"user\",\"features\", \"label\"])\n",
    "userDataDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+-----+--------------------+\n",
      "|           user|            features|label|      scaledFeatures|\n",
      "+---------------+--------------------+-----+--------------------+\n",
      "|   PopoffSierra|  [602.0,100.0,22.0]|    0|[-0.5511433475228...|\n",
      "|      dhenwikan| [935.0,241.0,234.0]|    0|[-0.5434584724786...|\n",
      "| JosephineAlice|[50516.0,828.0,20...|    0|[0.60075711180434...|\n",
      "|   JoseJaimes95|[11049.0,279.0,36...|    0|[-0.3100505860012...|\n",
      "|      lyriczbot|  [89519.0,5.0,20.0]|    0|[1.50085675549429...|\n",
      "|  grillmeeting1|     [99.0,90.0,4.0]|    0|[-0.5627514320490...|\n",
      "|bustercalamity1|    [99.0,104.0,5.0]|    0|[-0.5627514320490...|\n",
      "|    _Coopavelli|[223653.0,2309.0,...|    0|[4.59636134762072...|\n",
      "|     LeahEbooks|  [10578.0,1.0,28.0]|    0|[-0.3209201840367...|\n",
      "|   KeyOfConceit| [90.0,206.0,1571.0]|    0|[-0.5629591313746...|\n",
      "| goofy_goober33|      [1.0,25.0,2.0]|    0|[-0.5650130469269...|\n",
      "|      kalenstar|[28756.0,500.0,79...|    0|[0.09858629810557...|\n",
      "|        VBMagz4|[3040.0,601.0,286.0]|    0|[-0.4948799080101...|\n",
      "|   lizkennedyyy|[5195.0,761.0,125...|    0|[-0.4451474583997...|\n",
      "|       BRick441|[8796.0,1214.0,42...|    0|[-0.3620446504894...|\n",
      "|    Hello_Davey|[79458.0,1307.0,1...|    0|[1.26867198726711...|\n",
      "|mangledindustr1|   [121.0,119.0,5.0]|    0|[-0.5622437225867...|\n",
      "|  travisworland|[23909.0,1326.0,1...|    0|[-0.0132713275377...|\n",
      "|    PuffyPanda2|     [68.0,21.0,5.0]|    0|[-0.5634668408369...|\n",
      "|     thottinsos|[5747.0,2971.0,33...|    0|[-0.4324085664346...|\n",
      "+---------------+--------------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n",
    "                        withStd=True, withMean=True)\n",
    "scalerModel = scaler.fit(userDataDF)\n",
    "scaledData = scalerModel.transform(userDataDF)\n",
    "scaledData.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userSplits = scaledData.randomSplit([0.6, 0.4])\n",
    "userTraindf = userSplits[0]\n",
    "userTestdf = userSplits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userTrainData = userTraindf.select(\"label\", \"features\")\n",
    "userTestData = userTestdf.select(\"label\", \"features\")\n",
    "userTrainDataScaled = userTraindf.selectExpr(\"label\", \"scaledFeatures as features\")\n",
    "userTestDataScaled = userTestdf.selectExpr(\"label\", \"scaledFeatures as features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating unscaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_cvModel_3 = lr_cv.fit(userTrainData)\n",
    "lr_result_3 = lr_cvModel_3.transform(userTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5524193548387096"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_evaluator_3 = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "lr_evaluator_3.evaluate(lr_result_3, {lr_evaluator_3.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.519607843137\n",
      "recall:  0.890756302521\n",
      "specificity:  0.240310077519\n",
      "accuracy:  0.552419354839\n",
      "f1_score:  0.656346749226\n"
     ]
    }
   ],
   "source": [
    "result = lr_result_3.select(\"label\", \"prediction\").rdd.map(list)\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "print \"precision: \", precision \n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity \n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Scaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_cvModel_4 = lr_cv.fit(userTrainDataScaled)\n",
    "lr_result_4 = lr_cvModel_4.transform(userTestDataScaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5524193548387096"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_evaluator_4 = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "lr_evaluator_4.evaluate(lr_result_4, {lr_evaluator_4.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.519607843137\n",
      "recall:  0.890756302521\n",
      "specificity:  0.240310077519\n",
      "accuracy:  0.552419354839\n",
      "f1_score:  0.656346749226\n"
     ]
    }
   ],
   "source": [
    "result = lr_result_4.select(\"label\", \"prediction\").rdd.map(list)\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "print \"precision: \", precision \n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity \n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating unscaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_model_3 = cv.fit(userTrainData)\n",
    "nb_result_3 = nb_model_3.transform(userTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6169354838709677"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_evaluator_3 = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "nb_evaluator_3.evaluate(nb_result_3, {nb_evaluator_3.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.592307692308\n",
      "recall:  0.647058823529\n",
      "specificity:  0.589147286822\n",
      "accuracy:  0.616935483871\n",
      "f1_score:  0.618473895582\n"
     ]
    }
   ],
   "source": [
    "result = nb_result_3.select(\"label\", \"prediction\").rdd.map(list)\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "print \"precision: \", precision \n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity \n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Scaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_model_4 = cv.fit(userTrainData)\n",
    "nb_result_4 = nb_model_4.transform(userTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6169354838709677"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_evaluator_4 = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "nb_evaluator_4.evaluate(nb_result_4, {nb_evaluator_4.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.592307692308\n",
      "recall:  0.647058823529\n",
      "specificity:  0.589147286822\n",
      "accuracy:  0.616935483871\n",
      "f1_score:  0.618473895582\n"
     ]
    }
   ],
   "source": [
    "result = nb_result_4.select(\"label\", \"prediction\").rdd.map(list)\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "print \"precision: \", precision \n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity \n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers_2 = [3, 5, 4, 2]\n",
    "\n",
    "mlp_2 = MultilayerPerceptronClassifier(maxIter=100, layers=layers_2, blockSize=128, seed=1234)\n",
    "\n",
    "mlp_pipeline_2 = Pipeline(stages=[mlp_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating unscaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp_model_3 = mlp_pipeline_2.fit(userTrainData)\n",
    "mlp_result_3 = mlp_model_3.transform(userTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6370967741935484"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_evaluator_3 = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "mlp_evaluator_3.evaluate(mlp_result_3, {mlp_evaluator_3.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.698630136986\n",
      "recall:  0.428571428571\n",
      "specificity:  0.829457364341\n",
      "accuracy:  0.637096774194\n",
      "f1_score:  0.53125\n"
     ]
    }
   ],
   "source": [
    "result = mlp_result_3.select(\"label\", \"prediction\").rdd.map(list)\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "print \"precision: \", precision \n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity \n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Scaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp_model_4 = mlp_pipeline_2.fit(userTrainDataScaled)\n",
    "mlp_result_4 = mlp_model_4.transform(userTestDataScaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6008064516129032"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_evaluator_4 = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "mlp_evaluator_4.evaluate(mlp_result_4, {mlp_evaluator_4.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.578125\n",
      "recall:  0.621848739496\n",
      "specificity:  0.581395348837\n",
      "accuracy:  0.600806451613\n",
      "f1_score:  0.599190283401\n"
     ]
    }
   ],
   "source": [
    "result = mlp_result_4.select(\"label\", \"prediction\").rdd.map(list)\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "print \"precision: \", precision \n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity \n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating unscaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_model_3 = dt_cv.fit(userTrainData)\n",
    "dt_result_3 = dt_model_3.transform(userTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6008064516129032"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_evaluator_3 = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "dt_evaluator_3.evaluate(dt_result_3, {dt_evaluator_3.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.583333333333\n",
      "recall:  0.588235294118\n",
      "specificity:  0.612403100775\n",
      "accuracy:  0.600806451613\n",
      "f1_score:  0.585774058577\n"
     ]
    }
   ],
   "source": [
    "result = dt_result_3.select(\"label\", \"prediction\").rdd.map(list)\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "print \"precision: \", precision \n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity \n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating scaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_model_4 = dt_cv.fit(userTrainDataScaled)\n",
    "dt_result_4 = dt_model_4.transform(userTestDataScaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6008064516129032"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_evaluator_4 = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "dt_evaluator_4.evaluate(dt_result_4, {dt_evaluator_4.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.583333333333\n",
      "recall:  0.588235294118\n",
      "specificity:  0.612403100775\n",
      "accuracy:  0.600806451613\n",
      "f1_score:  0.585774058577\n"
     ]
    }
   ],
   "source": [
    "result = dt_result_4.select(\"label\", \"prediction\").rdd.map(list)\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "print \"precision: \", precision \n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity \n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Combination of classifiers through SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_column = lr_result_3.select(\"label\").collect()\n",
    "lr_column = lr_result_3.select(\"prediction\").collect()\n",
    "mlp_column = mlp_result_3.select(\"prediction\").collect()\n",
    "nb_column = nb_result_3.select(\"prediction\").collect()\n",
    "dt_column = dt_result_3.select(\"prediction\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp_label = [i[0] for i in label_column] \n",
    "temp_lr = [i[0] for i in lr_column]\n",
    "temp_mlp = [i[0] for i in mlp_column] \n",
    "temp_nb = [i[0] for i in nb_column] \n",
    "temp_dt = [i[0] for i in dt_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([temp_lr,temp_mlp, temp_nb, temp_dt]).transpose()\n",
    "y = np.array([temp_label]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learned_weights = learn_coefficients(X, y, 0.001, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned Weights for(without using normalized features):\n",
      "Logistic Regression -2.12687131776\n",
      "Multilayer Perceptron 1.10054567575\n",
      "Naive Bayes 1.28698299116\n",
      "Decision Tree 0.739342650854\n"
     ]
    }
   ],
   "source": [
    "print \"Learned Weights for(without using normalized features):\"\n",
    "print \"Logistic Regression\", learned_weights[0]/sum(learned_weights) \n",
    "print \"Multilayer Perceptron\", learned_weights[1]/sum(learned_weights) \n",
    "print \"Naive Bayes\", learned_weights[2]/sum(learned_weights)\n",
    "print \"Decision Tree\", learned_weights[3]/sum(learned_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_rbf.fit(X, np.ravel(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_rbf_predictions_2 = svm_rbf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.633720930233\n",
      "recall:  0.84496124031\n",
      "specificity:  0.470588235294\n",
      "accuracy:  0.665322580645\n",
      "f1_score:  0.724252491694\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y, svm_rbf_predictions_2).ravel()\n",
    "precision, recall, specificity, accuracy, f1_score = measures(tp,tn,fp,fn)\n",
    "print \"precision: \", precision \n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity \n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_lr_2 = linear_model.LogisticRegression(solver='lbfgs')\n",
    "meta_lr_2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_lr_predictions_2 = meta_lr_2.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.655405405405\n",
      "recall:  0.751937984496\n",
      "specificity:  0.571428571429\n",
      "accuracy:  0.665322580645\n",
      "f1_score:  0.70036101083\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y, meta_lr_predictions_2).ravel()\n",
    "precision, recall, specificity, accuracy, f1_score = measures(tp,tn,fp,fn)\n",
    "print \"precision: \", precision \n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity \n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_learned_weights_2 = meta_lr_2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned Weights for classifiers using logistic regression as the meta-classifier:\n",
      "Logistic Regression 0.370843180805\n",
      "Multilayer Perceptron 0.532148078738\n",
      "Naive Bayes -0.134881083998\n",
      "Decision Tree 0.231889824455\n"
     ]
    }
   ],
   "source": [
    "print \"Learned Weights for classifiers using logistic regression as the meta-classifier:\"\n",
    "print \"Logistic Regression\", meta_learned_weights[0][0]/sum(meta_learned_weights[0])\n",
    "print \"Multilayer Perceptron\", meta_learned_weights[0][1]/sum(meta_learned_weights[0])\n",
    "print \"Naive Bayes\", meta_learned_weights[0][2]/sum(meta_learned_weights[0])\n",
    "print \"Decision Tree\", meta_learned_weights[0][3]/sum(meta_learned_weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
