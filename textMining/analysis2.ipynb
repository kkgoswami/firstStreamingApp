{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from pyspark.context import SparkContext\n",
    "from os import path\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alltweets = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_connection(database):\n",
    "    try:\n",
    "        conn = sqlite3.connect(database)\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTweets(username): \n",
    "    sql = '''select tweet_text from tweets where user_screen_name=?'''\n",
    "    database = \"../twitterApp/twitter.sqlite\"\n",
    "    conn = create_connection(database)\n",
    "    \n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql,(username,))\n",
    "    \n",
    "    tweets = cur.fetchall()\n",
    "    \n",
    "    usertweets = []\n",
    "    \n",
    "    for tweet in tweets: \n",
    "        \n",
    "        usertweets.append((tweet[0]))\n",
    "    \n",
    "    #alltweets.extend(' '.join(usertweets))\n",
    "    \n",
    "    return usertweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTrueNegatives(database):\n",
    "    conn = create_connection(database)\n",
    "    sql = '''select user_screen_name from search_results where isDepressed=0 ORDER BY ROWID DESC LIMIT 322'''\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql)\n",
    "    users = cur.fetchall()\n",
    "    \n",
    "    return users\n",
    "    #for user in users: \n",
    "    #   user_tweets = getTweets(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTruePositives(database):    \n",
    "    conn = create_connection(database)\n",
    "    sql = '''select user_screen_name from search_results where isDepressed=\"True\"'''\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql)\n",
    "    users = cur.fetchall()\n",
    "    \n",
    "    return users\n",
    "    #for user in users: \n",
    "    #    user_tweets = getTweets(str(user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "\n",
    "def gettfidf(usertweets): \n",
    "    temp_df = spark.createDataFrame(usertweets,['tweet'])\n",
    "    tokenizer = Tokenizer(inputCol=\"tweet\", outputCol=\"words\")\n",
    "    wordsData = tokenizer.transform(temp_df)\n",
    "\n",
    "    hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=20)\n",
    "    featurizedData = hashingTF.transform(wordsData)\n",
    "    idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "    idfModel = idf.fit(featurizedData)\n",
    "    rescaledData = idfModel.transform(featurizedData)\n",
    "    \n",
    "    return rescaledData.select(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = getTruePositives(\"../twitterApp/twitter.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alltweets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_nonascii(text):\n",
    "    return ''.join([i if ord(i) < 128 else ' ' for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for user in test: \n",
    "    t = getTweets(user[0])    \n",
    "    alltweets.append(remove_nonascii(' '.join(t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the RDDs for users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trueNegatives = getTrueNegatives(\"../twitterApp/twitter.sqlite\")\n",
    "truePositives = getTruePositives(\"../twitterApp/twitter.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alltweets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for user in trueNegatives: \n",
    "    t = getTweets(user[0]) \n",
    "    alltweets.append([user[0], 0, remove_nonascii(' '.join(t))])\n",
    "\n",
    "for user in truePositives:\n",
    "    t = getTweets(user[0])\n",
    "    alltweets.append([user[0], 1, remove_nonascii(' '.join(t))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweetRDD = sc.parallelize(alltweets).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweetDF = tweetRDD.toDF([\"username\",\"label\",\"tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- username: string (nullable = true)\n",
      " |-- label: long (nullable = true)\n",
      " |-- tweet: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweetDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"tweet\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(tweetDF)\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=20)\n",
    "featurizedData = hashingTF.transform(wordsData)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "tfidftweets = idfModel.transform(featurizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|       username|label|               tweet|               words|         rawFeatures|            features|\n",
      "+---------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|   PopoffSierra|    0|RT @jacksfilms: \"...|[rt, @jacksfilms:...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|      dhenwikan|    0|Carnival and He -...|[carnival, and, h...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "| JosephineAlice|    0|Guess I'll just r...|[guess, i'll, jus...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|   JoseJaimes95|    0|Being able to mut...|[being, able, to,...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|      lyriczbot|    0|I miss that happy...|[i, miss, that, h...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|  grillmeeting1|    0|@1HkipUrdKrXXzdk ...|[@1hkipurdkrxxzdk...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|bustercalamity1|    0|@marcushegreat3 G...|[@marcushegreat3,...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|    _Coopavelli|    0|THE COOKOUT IS FR...|[the, cookout, is...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|     LeahEbooks|    0|?? the love good ...|[??, the, love, g...|(20,[0,1,2,4,5,6,...|(20,[0,1,2,4,5,6,...|\n",
      "|   KeyOfConceit|    0|@EthereaIVirago M...|[@ethereaivirago,...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "| goofy_goober33|    0|@Treyarch hey you...|[@treyarch, hey, ...|(20,[0,3,4,5,8,9,...|(20,[0,3,4,5,8,9,...|\n",
      "|      kalenstar|    0|gospel. let shit ...|[gospel., let, sh...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|        VBMagz4|    0|@EBJunkies coulda...|[@ebjunkies, coul...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|   lizkennedyyy|    0|RT @UberFacts: Re...|[rt, @uberfacts:,...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|       BRick441|    0|@Ian_height76 Hey...|[@ian_height76, h...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|    Hello_Davey|    0|@PRINCE_OF_NY For...|[@prince_of_ny, f...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|mangledindustr1|    0|@hleborezka1337 H...|[@hleborezka1337,...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|  travisworland|    0|What a day it has...|[what, a, day, it...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|    PuffyPanda2|    0|I should just mak...|[i, should, just,...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|     thottinsos|    0|@bizzleown ifb @A...|[@bizzleown, ifb,...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "+---------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidftweets.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized using L^1 norm\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|normFeatures                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.032591106549712826,0.08340048945781986,0.030010977281193896,0.05169725049954928,0.0413194205761345,0.05691590039224825,0.038161377340361284,0.07165100610495508,0.05608386252096416,0.05658973477395456,0.03725870605348249,0.05002066820424728,0.04276962486562839,0.10160059009848327,0.03620438363059918,0.027029534496298142,0.051466789093088175,0.04191228195073868,0.05313934799273264,0.04017694811780819])       |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.035531576354220364,0.07504515797872807,0.033661493388208764,0.03989061489087895,0.05057119630846068,0.07625203329007156,0.05603936247404978,0.051271327113606116,0.03490821536554983,0.054756018295254755,0.029928080741592415,0.0612629650802921,0.050185938664013434,0.08683962276513059,0.04470315556136033,0.030609863298618124,0.04390242391636751,0.03978366954264603,0.05141414418077494,0.053443140790175724])    |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.03593457569505255,0.048137332912243036,0.026537085665658933,0.05434921235597059,0.041780919515819255,0.05838640764634094,0.039209730017081765,0.04627580133996677,0.0691186665034533,0.07224132784738466,0.04219996678792248,0.05384853094324502,0.07275978556519638,0.07416817105415233,0.03596773985966315,0.023941104595599033,0.06308288022441189,0.047865232041133354,0.04852219946326612,0.04567332996643831])      |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.0350930201002845,0.050999597249113224,0.027673352993367206,0.041331728316347856,0.03848694623554719,0.05704561191513415,0.036665728397168015,0.049406390090078106,0.06489702074259754,0.06089882475161815,0.04506435203100827,0.055127900738559985,0.07469989098009065,0.08173025664885974,0.0374183090292938,0.028833997618119753,0.05464484558472872,0.056082308706013155,0.054833454908760404,0.04906646296330948])    |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.05495867978673711,0.052192964312467574,0.023192356977170033,0.05960837604747518,0.023797187205289443,0.08149127320979274,0.03784911107251535,0.05162944850080489,0.08819566568933969,0.07718180839332342,0.048006984548364405,0.05563251301572967,0.023312414845468435,0.06997581804447309,0.026404302871400116,0.03355200805293339,0.06838583382615133,0.04023344611441435,0.047714195667943486,0.03668561181820617])    |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.04560461444891344,0.0559530114921069,0.028502884030570903,0.04792224562363441,0.037968114941072544,0.0684603508909063,0.05305677194045238,0.04571169617538304,0.06555663327031307,0.03080715790090783,0.02732015848716392,0.13895815114336307,0.07746741738940371,0.03765319298999846,0.039364701762271116,0.05012597595784946,0.021377163022928174,0.03765319298999846,0.05256845060169049,0.037968114941072544])        |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.039613488419036794,0.06512243520938493,0.024587682466988357,0.03444964134258476,0.032561217604692466,0.06397790535051456,0.041011477788791384,0.037241961159475465,0.06146920616747089,0.041011477788791384,0.017184575616716335,0.1085248575415707,0.10700954594630144,0.04265193690034304,0.047573314234998006,0.039309629123131136,0.025953664826265488,0.057416068904307935,0.06353040433086991,0.049799509277764956])|\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.03523966369363943,0.05176896133310238,0.033015561496986166,0.04748457240305381,0.03700753059153503,0.05258916393638209,0.04798909598483626,0.037730078490200825,0.04752165026849132,0.050066546027469856,0.04352451956430687,0.049395946052505114,0.09480130907151589,0.10580156288555427,0.041163188701897266,0.025048564263947106,0.04828772991400521,0.049591700303439325,0.05564393928596844,0.04632871573116324])    |\n",
      "|(20,[0,1,2,4,5,6,8,9,10,12,13,14,15,16,17,18,19],[0.0556922631997938,0.13356055677577905,0.03635467181097651,0.01843817431127344,0.10775580582753995,0.010350927160773543,0.0556922631997938,0.08453257181298393,0.056201311034068335,0.0073315158482209295,0.06077852102095234,0.07378353206910372,0.011041439530453206,0.07834487025526549,0.05799173293920561,0.023392508307444534,0.12875733489637167])                                                                          |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.036573884081695845,0.05128350606153241,0.02767753389966172,0.055794005031382266,0.03187893620041204,0.06647796344164697,0.07478770887185282,0.058655617982482165,0.05930900121356082,0.04154872715102935,0.03316132026594191,0.060684773348696784,0.05452175232808903,0.06054243099149991,0.04867136609120581,0.03318715359101071,0.058320517860001475,0.046297153111146995,0.050729183119984575,0.049897465357166666])   |\n",
      "|(20,[0,3,4,5,8,9,10,15,16,17,18,19],[0.13413661008528827,0.0805448264805958,0.14106368169053088,0.1610896529611916,0.06706830504264413,0.0805448264805958,0.0803566369487923,0.026806412120002173,0.033534152521322066,0.0402724132402979,0.10756125519856213,0.04702122723017696])                                                                                                                                                                                                  |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.03633461261451775,0.05435343877060317,0.029667711217358537,0.043692779613046705,0.03842801475734904,0.05504489578214326,0.04323526359615616,0.040668124003502774,0.06014497474722926,0.05347218447408203,0.04078069115416455,0.05735262332007129,0.07916008937350884,0.09959551792685972,0.04354980585776841,0.025105111296864182,0.049692225770968906,0.04766745000978328,0.0562480250301968,0.04580646068382527])       |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.03944404162330052,0.04733666801310498,0.036270606882630244,0.044423818658652074,0.04709097596459405,0.049824819769256616,0.0477439145794566,0.04927055983463442,0.05692713608417113,0.057891249999380286,0.0458595619987104,0.05104345240764512,0.08542530794090919,0.07114825272540962,0.04164148475318913,0.02673723429449481,0.04690063981763621,0.04949748636861392,0.054828328941456304,0.050694459342754294])       |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.03133729925923136,0.05124612142454885,0.029419218080419845,0.04799985850115336,0.04201455061473651,0.054505675898521094,0.044824770584734656,0.03940779471315177,0.05894211622455923,0.06431109446393181,0.04462687268237287,0.06528913712039808,0.06746383345010842,0.08345500690116223,0.039003776071300365,0.026065572014814617,0.05938275649536728,0.04697262417525319,0.05150449119155595,0.05222743013267851])      |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.043197519419612175,0.04427358717138553,0.03838739702323422,0.04913528517349815,0.04967984618579301,0.061250527034667185,0.028680980732563418,0.038241151647085456,0.060304336035524445,0.04517928783107561,0.03684384860732483,0.0834402412631238,0.04739794708922429,0.08743653217058911,0.050753647722671005,0.025195120864347758,0.06414120409489209,0.0449095607395468,0.05147847337107657,0.05007350582276443])      |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.05035328447464929,0.05875530017194895,0.031391796597166295,0.04720178357656823,0.04628210795667487,0.051474964698449324,0.046386505599367224,0.04283626227347491,0.057656968694124226,0.044531045375392535,0.052616826347612014,0.05207503360125357,0.04897139452835449,0.08476079659520738,0.04464349751017888,0.03265383395184508,0.04480529357716353,0.05181232110280836,0.05988066461541847,0.05091031875234236])     |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.04409400273586092,0.06536117169338959,0.020157258393536423,0.04992818048870775,0.04946250830851103,0.05295413082135671,0.048415205322383276,0.024245506272955145,0.09826663466849005,0.019668677162218207,0.02415104263604847,0.1182895231767762,0.07855203452344132,0.034798428825462975,0.03631140399178746,0.03524770779898008,0.02771623029111258,0.0469022301560588,0.07071605996278583,0.05476206277013722])        |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.04029047258871348,0.04143195395865985,0.029471498315366735,0.045230033381296345,0.038211853910059344,0.05987770001832863,0.04182858778148341,0.04419595448629271,0.05708029587140727,0.06104215887231864,0.036701753791332684,0.059158439890455564,0.07485790188869995,0.10565931917256761,0.03450475446296726,0.030024749749364126,0.05646790110121782,0.0427172537490021,0.05004782623771851,0.051199590772748056])     |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.03515053270339997,0.05065680082494057,0.040032551134427746,0.0574573788034656,0.04654949264994538,0.07856417101698358,0.05276698053379494,0.028186454213147586,0.05858422117233328,0.05628477923604793,0.04503960379500859,0.03878676405623489,0.057758045018558836,0.08325456928665423,0.029314989185441634,0.025756966021789753,0.050772991682688846,0.04455878356187128,0.054806994303342536,0.0657169307999229])      |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.03733252723698539,0.047842338976585394,0.0292577350577866,0.049386875553271634,0.0380215951941978,0.05141893970364062,0.04480830063218707,0.04142627101067949,0.06633323973203886,0.051984830986021864,0.03998175729141533,0.058823474706450135,0.0750434564274028,0.09964831036113245,0.03595981876222591,0.028044987822971885,0.05039784084258555,0.04534846958355098,0.06220810679961904,0.046731123319251014])        |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "normalizer = Normalizer(inputCol=\"features\", outputCol=\"normFeatures\", p=1.0)\n",
    "l1NormData = normalizer.transform(tfidftweets)\n",
    "print(\"Normalized using L^1 norm\")\n",
    "l1NormData.select(\"normFeatures\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "def measures(tp,tn,fp,fn):\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    specificity = tn/(tn+fp)\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    f1_score = (2*tp)/((2*tp)+fp+fn)\n",
    "    return precision, recall, specificity, accuracy, f1_score\n",
    "\n",
    "def howgoodisit(result):\n",
    "    true_positives = result.filter(lambda line: line[1]==0.0 and line[0]==0.0).count()\n",
    "    true_negatives = result.filter(lambda line: line[1]==1.0 and line[0]==1.0).count()\n",
    "    false_positives = result.filter(lambda line: line[1]==0.0 and line[0]==1.0).count()\n",
    "    false_negatives = result.filter(lambda line: line[1]==1.0 and line[0]==0.0).count()\n",
    "    return measures(true_positives, true_negatives, false_positives, false_negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating NormFeatures and TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splits = l1NormData.randomSplit([0.6, 0.4])\n",
    "training_df = splits[0]\n",
    "test_df = splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = (LogisticRegression()).setMaxIter(1000).setRegParam(0.01)\n",
    "\n",
    "lr_pipeline = Pipeline(stages=[lr])\n",
    "\n",
    "lr_paramGrid = ParamGridBuilder().addGrid(lr.regParam, [0.01, 0.1, 0.5,1.0, 2.0]).build()\n",
    "\n",
    "lr_cv = CrossValidator(estimator=lr_pipeline, \n",
    "                    estimatorParamMaps=lr_paramGrid, \n",
    "                    evaluator=MulticlassClassificationEvaluator(), \n",
    "                    numFolds=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainData = training_df.select(\"label\", \"features\")\n",
    "testData = test_df.select(\"label\", \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_cvModel1 = lr_cv.fit(trainData)\n",
    "lr_result1 = lr_cvModel1.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6327272727272727"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "lr_evaluator.evaluate(lr_result1, {lr_evaluator.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.63768115942\n",
      "recall:  0.63309352518\n",
      "specificity:  0.632352941176\n",
      "accuracy:  0.632727272727\n",
      "f1_score:  0.635379061372\n"
     ]
    }
   ],
   "source": [
    "result = lr_result1.select(\"label\", \"prediction\").rdd.map(list)\n",
    "\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "\n",
    "print \"precision: \", precision\n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity\n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating L1 Norm features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L1trainData = training_df.selectExpr(\"label\", \"normFeatures as features\")\n",
    "L1testData = test_df.selectExpr(\"label\", \"normFeatures as features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_cvModel2 = lr_cv.fit(L1trainData)\n",
    "lr_result2 = lr_cvModel2.transform(L1testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6436363636363637"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_evaluator_norm = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "lr_evaluator_norm.evaluate(lr_result2, {lr_evaluator_norm.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.672268907563\n",
      "recall:  0.575539568345\n",
      "specificity:  0.713235294118\n",
      "accuracy:  0.643636363636\n",
      "f1_score:  0.62015503876\n"
     ]
    }
   ],
   "source": [
    "result = lr_result2.select(\"label\", \"prediction\").rdd.map(list)\n",
    "\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "\n",
    "print \"precision: \", precision\n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity\n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb = NaiveBayes()\n",
    "pipeline = Pipeline(stages=[nb])\n",
    "paramGrid = ParamGridBuilder().addGrid(nb.smoothing, [0.0, 1.0]).build()\n",
    "\n",
    "\n",
    "cv = CrossValidator(estimator=pipeline, \n",
    "                    estimatorParamMaps=paramGrid, \n",
    "                    evaluator=MulticlassClassificationEvaluator(), \n",
    "                    numFolds=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_model1 = cv.fit(trainData)\n",
    "nb_result = nb_model1.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5345454545454545"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_evaluator_1 = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "nb_evaluator_1.evaluate(nb_result, {nb_evaluator_1.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.526570048309\n",
      "recall:  0.784172661871\n",
      "specificity:  0.279411764706\n",
      "accuracy:  0.534545454545\n",
      "f1_score:  0.630057803468\n"
     ]
    }
   ],
   "source": [
    "result = nb_result.select(\"label\", \"prediction\").rdd.map(list)\n",
    "\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "\n",
    "print \"precision: \", precision\n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity\n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating L1-Norm Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_model2 = cv.fit(L1trainData)\n",
    "nb_result_2 = nb_model2.transform(L1testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5381818181818182"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_evaluator_2 = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "nb_evaluator_2.evaluate(nb_result_2, {nb_evaluator_2.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  1.0\n",
      "recall:  0.0863309352518\n",
      "specificity:  1.0\n",
      "accuracy:  0.538181818182\n",
      "f1_score:  0.158940397351\n"
     ]
    }
   ],
   "source": [
    "result = nb_result_2.select(\"label\", \"prediction\").rdd.map(list)\n",
    "\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "\n",
    "print \"precision: \", precision\n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity\n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "dt_pipeline = Pipeline(stages=[dt])\n",
    "dt_paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(dt.maxDepth, [1,2,6,10])\n",
    "             .addGrid(dt.maxBins, [20,40,80])\n",
    "             .build())\n",
    "\n",
    "dt_cv = CrossValidator(estimator=dt_pipeline, \n",
    "                    estimatorParamMaps=dt_paramGrid, \n",
    "                    evaluator=MulticlassClassificationEvaluator(), \n",
    "                    numFolds=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_model_1 = dt_cv.fit(trainData)\n",
    "dt_result_1 = dt_model_1.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5927272727272728"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_evaluator_1 = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "dt_evaluator_1.evaluate(dt_result_1, {dt_evaluator_1.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.58282208589\n",
      "recall:  0.68345323741\n",
      "specificity:  0.5\n",
      "accuracy:  0.592727272727\n",
      "f1_score:  0.629139072848\n"
     ]
    }
   ],
   "source": [
    "result = dt_result_1.select(\"label\", \"prediction\").rdd.map(list)\n",
    "\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "\n",
    "print \"precision: \", precision\n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity\n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating L1-Norm features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_model_2 = dt_cv.fit(L1trainData)\n",
    "dt_result_2 = dt_model_2.transform(L1testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5890909090909091"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_evaluator_2 = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "dt_evaluator_2.evaluate(dt_result_2, {dt_evaluator_2.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.62037037037\n",
      "recall:  0.482014388489\n",
      "specificity:  0.698529411765\n",
      "accuracy:  0.589090909091\n",
      "f1_score:  0.542510121457\n"
     ]
    }
   ],
   "source": [
    "result = dt_result_2.select(\"label\", \"prediction\").rdd.map(list)\n",
    "\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "\n",
    "print \"precision: \", precision\n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity\n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers = [20, 5, 4, 2]\n",
    "\n",
    "mlp = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "\n",
    "mlp_pipeline = Pipeline(stages=[mlp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp_model_1 = mlp_pipeline.fit(trainData)\n",
    "mlp_result_1 = mlp_model_1.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5963636363636363"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "mlp_evaluator.evaluate(mlp_result_1, {mlp_evaluator.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.586419753086\n",
      "recall:  0.68345323741\n",
      "specificity:  0.507352941176\n",
      "accuracy:  0.596363636364\n",
      "f1_score:  0.63122923588\n"
     ]
    }
   ],
   "source": [
    "result = mlp_result_1.select(\"label\", \"prediction\").rdd.map(list)\n",
    "\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "\n",
    "print \"precision: \", precision\n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity\n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating L1-Norm Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp_model_2 = mlp_pipeline.fit(L1trainData)\n",
    "mlp_result_2 = mlp_model_2.transform(L1testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6727272727272727"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_evaluator_2 = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "mlp_evaluator_2.evaluate(mlp_result_2, {mlp_evaluator_2.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.757894736842\n",
      "recall:  0.517985611511\n",
      "specificity:  0.830882352941\n",
      "accuracy:  0.672727272727\n",
      "f1_score:  0.615384615385\n"
     ]
    }
   ],
   "source": [
    "result = mlp_result_2.select(\"label\", \"prediction\").rdd.map(list)\n",
    "\n",
    "precision, recall, specificity, accuracy, f1_score = howgoodisit(result)\n",
    "\n",
    "print \"precision: \", precision\n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity\n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sgd import learn_coefficients\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the different classifier outputs to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-0.0036995367057...|[0.49907511687843...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-0.9922911163698...|[0.27045977686482...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[0.68244596516296...|[0.66428439266346...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[1.22774176661866...|[0.77342308623081...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[0.56800795812552...|[0.63830339494098...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-1.0007345973081...|[0.26879701529034...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[1.18987142502024...|[0.76671806790702...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-0.2807579648069...|[0.43026796069406...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-0.0013599346115...|[0.49966001639949...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[0.73303748701655...|[0.67547147395577...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[0.39620403860365...|[0.59777529890832...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-0.0785548905700...|[0.48037137013113...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-0.0837332865737...|[0.47907890053977...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-0.5786254288743...|[0.35924894375589...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[1.49579566258358...|[0.81694657674437...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-0.1704556327051...|[0.45748897227461...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-0.6280275947723...|[0.34795790911552...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-0.3272989827513...|[0.41889796702592...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[0.71969058694583...|[0.67253887856523...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-0.6580563802465...|[0.34117635381805...|       1.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_result1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-718.58593357458...|[0.05490157636335...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-1113.4349500029...|[0.87486860228217...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-745.78690531928...|[0.09762173690099...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-1238.7617135250...|[0.99824930408976...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-1387.1212484201...|[0.99937252957515...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-1635.3387090240...|[0.98502525072148...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-1169.9186747404...|[0.93391376051773...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-920.56844999794...|[0.77661013211230...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-747.01153742449...|[0.00143805088426...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-24.278982139020...|[0.51942751959075...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-687.37972858970...|[0.37111292779279...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-908.96497144596...|[0.90775388684377...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-1486.5620227145...|[0.97594510245918...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-969.39576778675...|[0.62096249626807...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-759.51105045666...|[0.98691388454396...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-1605.1132254919...|[0.99630063605176...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-1077.6721590231...|[9.81007406529173...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-1130.9741472962...|[0.47081627868872...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-24.414940794802...|[0.51373159873884...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|[-1093.1417124927...|[0.99539152539197...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-------------+--------------------+----------+\n",
      "|label|            features|rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+-------------+--------------------+----------+\n",
      "|    0|(20,[0,1,2,3,4,5,...| [100.0,83.0]|[0.54644808743169...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...| [47.0,101.0]|[0.31756756756756...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...| [100.0,83.0]|[0.54644808743169...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...| [47.0,101.0]|[0.31756756756756...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...| [47.0,101.0]|[0.31756756756756...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...| [47.0,101.0]|[0.31756756756756...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...| [100.0,83.0]|[0.54644808743169...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...| [47.0,101.0]|[0.31756756756756...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...| [100.0,83.0]|[0.54644808743169...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...| [100.0,83.0]|[0.54644808743169...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...| [100.0,83.0]|[0.54644808743169...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...| [100.0,83.0]|[0.54644808743169...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...| [47.0,101.0]|[0.31756756756756...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...| [47.0,101.0]|[0.31756756756756...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...| [100.0,83.0]|[0.54644808743169...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...| [47.0,101.0]|[0.31756756756756...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...| [100.0,83.0]|[0.54644808743169...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...| [47.0,101.0]|[0.31756756756756...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...| [100.0,83.0]|[0.54644808743169...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...| [47.0,101.0]|[0.31756756756756...|       1.0|\n",
      "+-----+--------------------+-------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_result_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+----------+\n",
      "|label|            features|prediction|\n",
      "+-----+--------------------+----------+\n",
      "|    0|(20,[0,1,2,3,4,5,...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       0.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       1.0|\n",
      "|    0|(20,[0,1,2,3,4,5,...|       1.0|\n",
      "+-----+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp_result_1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Combination of Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_column = lr_result1.select(\"label\").collect()\n",
    "lr_column = lr_result1.select(\"prediction\").collect()\n",
    "mlp_column = mlp_result_1.select(\"prediction\").collect()\n",
    "nb_column = nb_result.select(\"prediction\").collect()\n",
    "dt_column = dt_result_1.select(\"prediction\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp_label = [i[0] for i in label_column]\n",
    "temp_lr = [i[0] for i in lr_column]\n",
    "temp_mlp = [i[0] for i in mlp_column]\n",
    "temp_nb = [i[0] for i in nb_column]\n",
    "temp_dt = [i[0] for i in dt_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array([temp_lr,temp_mlp, temp_nb, temp_dt]).transpose()\n",
    "y = np.array([temp_label]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learned_weights = learn_coefficients(X, y, 0.001, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned Weights for(without using normalized features):\n",
      "Logistic Regression 0.186848353761\n",
      "Multilayer Perceptron 0.288891432644\n",
      "Naive Bayes 0.333243064381\n",
      "Decision Tree 0.267154165881\n"
     ]
    }
   ],
   "source": [
    "print \"Learned Weights for(without using normalized features):\"\n",
    "print \"Logistic Regression\", learned_weights[0]\n",
    "print \"Multilayer Perceptron\", learned_weights[1]\n",
    "print \"Naive Bayes\", learned_weights[2]\n",
    "print \"Decision Tree\", learned_weights[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining the classifier outputs with the help of another classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Using sklearn SVM here as Spark doesn't support SVM with RBF\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_rbf = svm.SVC()\n",
    "svm_rbf.fit(X,np.ravel(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_rbf_predictions = svm_rbf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.627737226277\n",
      "recall:  0.632352941176\n",
      "specificity:  0.63309352518\n",
      "accuracy:  0.632727272727\n",
      "f1_score:  0.630036630037\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y, svm_rbf_predictions).ravel()\n",
    "\n",
    "precision, recall, specificity, accuracy, f1_score = measures(tp,tn,fp,fn)\n",
    "\n",
    "print \"precision: \", precision\n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity\n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combination of classifiers with logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_lr = linear_model.LogisticRegression(solver='lbfgs')\n",
    "meta_lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_lr_predictions = meta_lr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.646616541353\n",
      "recall:  0.632352941176\n",
      "specificity:  0.661870503597\n",
      "accuracy:  0.647272727273\n",
      "f1_score:  0.639405204461\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y, meta_lr_predictions).ravel()\n",
    "\n",
    "precision, recall, specificity, accuracy, f1_score = measures(tp,tn,fp,fn)\n",
    "\n",
    "print \"precision: \", precision\n",
    "print \"recall: \", recall\n",
    "print \"specificity: \", specificity\n",
    "print \"accuracy: \", accuracy\n",
    "print \"f1_score: \", f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned Weights for classifiers using logistic regression as the meta-classifier:\n",
      "Logistic Regression 0.667609742943\n",
      "Multilayer Perceptron 0.545491285197\n",
      "Naive Bayes 0.44523088225\n",
      "Decision Tree 0.394552896063\n"
     ]
    }
   ],
   "source": [
    "meta_learned_weights = meta_lr.coef_\n",
    "\n",
    "print \"Learned Weights for classifiers using logistic regression as the meta-classifier:\"\n",
    "print \"Logistic Regression\", meta_learned_weights[0][0]\n",
    "print \"Multilayer Perceptron\", meta_learned_weights[0][1]\n",
    "print \"Naive Bayes\", meta_learned_weights[0][2]\n",
    "print \"Decision Tree\", meta_learned_weights[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
